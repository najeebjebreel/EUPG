{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d3343a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import copy\n",
    "from collections import Counter\n",
    "import csv\n",
    "import scipy\n",
    "\n",
    "\n",
    "from utils import *\n",
    "from datasets import *\n",
    "from mdav import *\n",
    "from train import *\n",
    "from models import *\n",
    "from attacks import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1531e761",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning, FitFailedWarning\n",
    "\n",
    "# Filter out ConvergenceWarning and FitFailedWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FitFailedWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Assuming y_test and y_forget are arrays of class indices\n",
    "encoder = OneHotEncoder(sparse_output=False, categories=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd6937e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def seed_everything(seed=7):\n",
    "#     np.random.seed(seed)\n",
    "#     np.random.seed(seed)\n",
    "#     random.seed(seed)\n",
    "#     torch.manual_seed(seed)\n",
    "#     torch.cuda.manual_seed(seed)\n",
    "#     torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "# seed_everything(seed=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba412321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Get dataset\n",
    "\n",
    "df=pd.read_csv('data/GiveMeSomeCredit/cs-training.csv')\n",
    "df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "y = df['SeriousDlqin2yrs'].values\n",
    "df.drop(df[['SeriousDlqin2yrs']],axis=1,inplace=True)\n",
    "X = df.values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "SC = StandardScaler()\n",
    "X_train = SC.fit_transform(X_train)\n",
    "X_test = SC.transform(X_test)\n",
    "\n",
    "counter = Counter(y_train)\n",
    "for k,v in counter.items():\n",
    "    per = v / len(y_train) * 100\n",
    "    print('Class=%s, Count=%d, Percentage=%.2f%%' % (k, v, per))\n",
    "    \n",
    "num_features = X_train.shape[-1]\n",
    "num_classes = len(set(y_train))\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "initial_model = XGBClassifier(num_classes= num_classes, reg_lambda=5, \n",
    "                              learning_rate=0.5, max_depth=9, n_estimators=200, device = device)\n",
    "n_repeat = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61c4606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly sample retain and forget sets\n",
    "forget_ratios = [0.05, 0.2, 0.5]\n",
    "for forget_ratio in forget_ratios:\n",
    "    idxs = np.arange(len(y_train))\n",
    "    random.shuffle(idxs)\n",
    "    m = int(len(y_train)*forget_ratio)\n",
    "    retain_idxs = idxs[m:]\n",
    "    forget_idxs = idxs[:m]\n",
    "    X_retain = X_train[retain_idxs]\n",
    "    y_retain = y_train[retain_idxs]\n",
    "    X_forget = X_train[forget_idxs]\n",
    "    y_forget = y_train[forget_idxs]\n",
    "\n",
    "    # Step 2: Define and train M on D\n",
    "    train_accs = []\n",
    "    test_accs = []\n",
    "    mia_aucs = []\n",
    "    mia_advs = []\n",
    "    runtimes = []\n",
    "\n",
    "    for r in range(n_repeat):\n",
    "        model = copy.deepcopy(initial_model)\n",
    "        t0 = time.time()\n",
    "        torch.cuda.empty_cache()\n",
    "        model.fit(X_train, y_train)\n",
    "        t1 = time.time()\n",
    "        rt = t1-t0\n",
    "        runtimes.append(rt)\n",
    "\n",
    "        # Evaluate the model accuracy, and MIA\n",
    "        # Accuracy\n",
    "        train_acc = roc_auc_score(y_train, model.predict_proba(X_train)[:, 1])\n",
    "        test_acc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "        train_accs.append(100.0*train_acc)\n",
    "        test_accs.append(100.0*test_acc)\n",
    "        #MIA\n",
    "        idxs = np.arange(len(y_test))\n",
    "        random.shuffle(idxs)\n",
    "        rand_idxs = idxs[:m]\n",
    "\n",
    "        test_preds = model.predict_proba(X_test)\n",
    "        forget_preds = model.predict_proba(X_forget)\n",
    "\n",
    "        # Convert class indices to one-hot encoding\n",
    "        y_test_one_hot = encoder.fit_transform(y_test.reshape(-1, 1))\n",
    "        y_forget_one_hot = encoder.transform(y_forget.reshape(-1, 1))\n",
    "\n",
    "        loss_test = np.array([metrics.log_loss(y_test_one_hot[i], test_preds[i]) for i in range(len(y_test))])\n",
    "        loss_forget = np.array([metrics.log_loss(y_forget_one_hot[i], forget_preds[i]) for i in range(len(y_forget))])\n",
    "\n",
    "        attack_result = tf_attack(logits_train = forget_preds, logits_test = test_preds[rand_idxs], \n",
    "                                  loss_train = loss_forget, loss_test = loss_test[rand_idxs], \n",
    "                                  train_labels = y_forget, test_labels = y_test[rand_idxs])\n",
    "\n",
    "        auc = attack_result.get_result_with_max_auc().get_auc()\n",
    "        adv = attack_result.get_result_with_max_attacker_advantage().get_attacker_advantage()\n",
    "        mia_aucs.append(100.0*auc)\n",
    "        mia_advs.append(100.0*adv)\n",
    "\n",
    "    mean_runtime = np.mean(runtimes)\n",
    "    std_runtime = np.std(runtimes)\n",
    "    mean_train_acc = np.mean(train_accs)\n",
    "    std_train_acc = np.std(train_accs)\n",
    "    mean_test_acc = np.mean(test_accs)\n",
    "    std_test_acc = np.std(test_accs)\n",
    "    mean_mia_auc = np.mean(mia_aucs)\n",
    "    std_mia_auc = np.std(mia_aucs)\n",
    "    mean_mia_adv = np.mean(mia_advs)\n",
    "    std_mia_adv = np.std(mia_advs)\n",
    "\n",
    "    # Print the results\n",
    "    print('Training M on D time:{:0.2f}(±{:0.2f}) seconds'.format(mean_runtime, std_runtime))\n",
    "    print('Train AUC:{:0.2f}(±{:0.2f})%'.format(mean_train_acc, std_train_acc))\n",
    "    print('Test AUC:{:0.2f}(±{:0.2f})%'.format(mean_test_acc, std_test_acc))\n",
    "    print('MIA AUC:{:0.2f}(±{:0.2f})%'.format(mean_mia_auc, std_mia_auc))\n",
    "    print('MIA Advantage:{:0.2f}(±{:0.2f})%'.format(mean_mia_adv, std_mia_adv))\n",
    "\n",
    "    # Save to CSV\n",
    "    csv_file_path = 'results/credit/xgb_m_d_fr={}.csv'.format(forget_ratio)\n",
    "\n",
    "    with open(csv_file_path, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Metric', 'Mean', 'Standard Deviation'])\n",
    "        writer.writerow(['Training Time', mean_runtime, std_runtime])\n",
    "        writer.writerow(['Train AUC', mean_train_acc, std_train_acc])\n",
    "        writer.writerow(['Test AUC', mean_test_acc, std_test_acc])\n",
    "        writer.writerow(['MIA AUC', mean_mia_auc, std_mia_auc])\n",
    "        writer.writerow(['MIA Advantage', mean_mia_adv, std_mia_adv])\n",
    "\n",
    "    ######################################################################################################\n",
    "    # Step 3: Train M_retain on D_retain\n",
    "    retain_accs = []\n",
    "    forget_accs = []\n",
    "    test_accs = []\n",
    "    mia_aucs = []\n",
    "    mia_advs = []\n",
    "    runtimes = []\n",
    "    for r in range(n_repeat):\n",
    "        model_ret = copy.deepcopy(initial_model)\n",
    "        t0 = time.time()\n",
    "        torch.cuda.empty_cache()\n",
    "        model_ret.fit(X_retain, y_retain)\n",
    "        t1 = time.time()\n",
    "        rt = t1-t0\n",
    "        runtimes.append(rt)\n",
    "\n",
    "        # Evaluate the model accuracy, and MIA\n",
    "        # Accuracy\n",
    "        retain_acc = roc_auc_score(y_retain, model_ret.predict_proba(X_retain)[:, 1])\n",
    "        forget_acc = roc_auc_score(y_forget, model_ret.predict_proba(X_forget)[:, 1])\n",
    "        test_acc = roc_auc_score(y_test, model_ret.predict_proba(X_test)[:, 1])\n",
    "        retain_accs.append(100.0*retain_acc)\n",
    "        forget_accs.append(100.0*forget_acc)\n",
    "        test_accs.append(100.0*test_acc)\n",
    "        #MIA\n",
    "        idxs = np.arange(len(y_test))\n",
    "        random.shuffle(idxs)\n",
    "        rand_idxs = idxs[:m]\n",
    "\n",
    "        test_preds = model_ret.predict_proba(X_test)\n",
    "        forget_preds = model_ret.predict_proba(X_forget)\n",
    "        loss_test = np.array([metrics.log_loss(y_test_one_hot[i], test_preds[i]) for i in range(len(y_test))])\n",
    "        loss_forget = np.array([metrics.log_loss(y_forget_one_hot[i], forget_preds[i]) for i in range(len(y_forget))])\n",
    "\n",
    "        attack_result = tf_attack(logits_train = forget_preds, logits_test = test_preds[rand_idxs], \n",
    "                                  loss_train = loss_forget, loss_test = loss_test[rand_idxs], \n",
    "                                  train_labels = y_forget, test_labels = y_test[rand_idxs])\n",
    "\n",
    "        auc = attack_result.get_result_with_max_auc().get_auc()\n",
    "        adv = attack_result.get_result_with_max_attacker_advantage().get_attacker_advantage()\n",
    "        mia_aucs.append(100.0*auc)\n",
    "        mia_advs.append(100.0*adv)\n",
    "\n",
    "\n",
    "    mean_retrain_runtime = np.mean(runtimes)\n",
    "    std_retrain_runtime = np.std(runtimes)\n",
    "    mean_retain_acc = np.mean(retain_accs)\n",
    "    std_retain_acc = np.std(retain_accs)\n",
    "    mean_forget_acc = np.mean(forget_accs)\n",
    "    std_forget_acc = np.std(forget_accs)\n",
    "    mean_retrain_test_acc = np.mean(test_accs)\n",
    "    std_retrain_test_acc = np.std(test_accs)\n",
    "    mean_retrain_mia_auc = np.mean(mia_aucs)\n",
    "    std_retrain_mia_auc = np.std(mia_aucs)\n",
    "    mean_retrain_mia_adv = np.mean(mia_advs)\n",
    "    std_retrain_mia_adv = np.std(mia_advs)\n",
    "\n",
    "    # Print the results\n",
    "    print('Retraining M on D_ret time:{:0.2f}(±{:0.2f}) seconds'.format(mean_retrain_runtime, std_retrain_runtime))\n",
    "    print('Retain AUC:{:0.2f}(±{:0.2f})%'.format(mean_retain_acc, std_retain_acc))\n",
    "    print('Forget AUC:{:0.2f}(±{:0.2f})%'.format(mean_forget_acc, std_forget_acc))\n",
    "    print('Test AUC:{:0.2f}(±{:0.2f})%'.format(mean_retrain_test_acc, std_retrain_test_acc))\n",
    "    print('MIA AUC:{:0.2f}(±{:0.2f})%'.format(mean_retrain_mia_auc, std_retrain_mia_auc))\n",
    "    print('MIA Advantage:{:0.2f}(±{:0.2f})%'.format(mean_retrain_mia_adv, std_retrain_mia_adv))\n",
    "\n",
    "    # Save to CSV\n",
    "    csv_retrain_file_path = 'results/credit/xgb_mret_dret_fr={}.csv'.format(forget_ratio)\n",
    "\n",
    "    with open(csv_retrain_file_path, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Metric', 'Mean', 'Standard Deviation'])\n",
    "        writer.writerow(['Retraining Time', mean_retrain_runtime, std_retrain_runtime])\n",
    "        writer.writerow(['Retain AUC', mean_retain_acc, std_retain_acc])\n",
    "        writer.writerow(['Forget AUC', mean_forget_acc, std_forget_acc])\n",
    "        writer.writerow(['Test AUC', mean_retrain_test_acc, std_retrain_test_acc])\n",
    "        writer.writerow(['MIA AUC', mean_retrain_mia_auc, std_retrain_mia_auc])\n",
    "        writer.writerow(['MIA Advantage', mean_retrain_mia_adv, std_retrain_mia_adv])\n",
    "        \n",
    "# ######################################################################################################\n",
    "    # Step 1: k-anonymize and prepare D_k\n",
    "    ft_epochs_list = [5]\n",
    "    for ft_epochs in ft_epochs_list:\n",
    "        K = [10]\n",
    "        for k in K:\n",
    "            runtimes_k = []\n",
    "            t0 = time.time()\n",
    "            centroids, clusters, labels, X_train_k, y_train_k = mdav(copy.deepcopy(X_train), copy.deepcopy(y_train), k)\n",
    "            print_stats(clusters, centroids)\n",
    "            print('Shape of X_train_k:{}, y_train_k:{}'.format(X_train_k.shape, y_train_k.shape))\n",
    "             # Create TensorDatasets\n",
    "            t1 = time.time()\n",
    "            rt_k = t1- t0\n",
    "            runtimes_k.append(rt_k)\n",
    "\n",
    "            train_accs_k = []\n",
    "            test_accs_k = []\n",
    "            mia_aucs_k = []\n",
    "            mia_advs_k = []\n",
    "            runtimes_train_k = []\n",
    "\n",
    "            train_accs_k_D = []\n",
    "            test_accs_k_D = []\n",
    "            mia_aucs_k_D = []\n",
    "            mia_advs_k_D = []\n",
    "            runtimes_train_k_D = []\n",
    "\n",
    "            retain_accs_k_ret = []\n",
    "            forget_accs_k_ret = []\n",
    "            test_accs_k_ret = []\n",
    "            mia_aucs_k_ret = []\n",
    "            mia_advs_k_ret = []\n",
    "            runtimes_train_k_ret = []\n",
    "\n",
    "            for r in range(n_repeat):\n",
    "                model_k = copy.deepcopy(initial_model)\n",
    "                t0 = time.time()\n",
    "                torch.cuda.empty_cache()\n",
    "                model_k.fit(X_train_k, y_train_k)\n",
    "                t1 = time.time()\n",
    "                rt_train = t1- t0\n",
    "                runtimes_train_k.append(rt_train)\n",
    "\n",
    "                # Evaluate the model accuracy, and MIA\n",
    "                # Accuracy\n",
    "                train_acc = roc_auc_score(y_train_k, model_k.predict_proba(X_train_k)[:, 1])\n",
    "                test_acc = roc_auc_score(y_test, model_k.predict_proba(X_test)[:, 1])\n",
    "                train_accs_k.append(100.0*train_acc)\n",
    "                test_accs_k.append(100.0*test_acc)\n",
    "                #MIA\n",
    "                idxs = np.arange(len(y_test))\n",
    "                random.shuffle(idxs)\n",
    "                rand_idxs = idxs[:m]\n",
    "\n",
    "                test_preds = model_k.predict_proba(X_test)\n",
    "                forget_preds = model_k.predict_proba(X_forget)\n",
    "\n",
    "                # Convert class indices to one-hot encoding\n",
    "                y_test_one_hot = encoder.fit_transform(y_test.reshape(-1, 1))\n",
    "                y_forget_one_hot = encoder.transform(y_forget.reshape(-1, 1))\n",
    "\n",
    "                loss_test = np.array([metrics.log_loss(y_test_one_hot[i], test_preds[i]) for i in range(len(y_test))])\n",
    "                loss_forget = np.array([metrics.log_loss(y_forget_one_hot[i], forget_preds[i]) for i in range(len(y_forget))])\n",
    "\n",
    "                attack_result = tf_attack(logits_train = forget_preds, logits_test = test_preds[rand_idxs], \n",
    "                                          loss_train = loss_forget, loss_test = loss_test[rand_idxs], \n",
    "                                          train_labels = y_forget, test_labels = y_test[rand_idxs])\n",
    "\n",
    "                auc = attack_result.get_result_with_max_auc().get_auc()\n",
    "                adv = attack_result.get_result_with_max_attacker_advantage().get_attacker_advantage()\n",
    "                mia_aucs_k.append(100.0*auc)\n",
    "                mia_advs_k.append(100.0*adv)\n",
    "\n",
    "                model_k_D = copy.deepcopy(initial_model)\n",
    "                model_k_D.set_params(learning_rate = 0.5, n_estimators=ft_epochs)\n",
    "                t0 = time.time()\n",
    "                torch.cuda.empty_cache()\n",
    "                model_k_D.fit(X_train, y_train, xgb_model=model_k)\n",
    "                t1 = time.time()\n",
    "                rt = t1-t0\n",
    "                runtimes_train_k_D.append(rt)\n",
    "\n",
    "                # Evaluate the model accuracy, and MIA\n",
    "                # Accuracy\n",
    "                train_acc = roc_auc_score(y_train, model_k_D.predict_proba(X_train)[:, 1])\n",
    "                test_acc = roc_auc_score(y_test, model_k_D.predict_proba(X_test)[:, 1])\n",
    "                train_accs_k_D.append(100.0*train_acc)\n",
    "                test_accs_k_D.append(100.0*test_acc)\n",
    "                #MIA\n",
    "                idxs = np.arange(len(y_test))\n",
    "                random.shuffle(idxs)\n",
    "                rand_idxs = idxs[:m]\n",
    "\n",
    "                test_preds = model_k_D.predict_proba(X_test)\n",
    "                forget_preds = model_k_D.predict_proba(X_forget)\n",
    "\n",
    "                # Convert class indices to one-hot encoding\n",
    "                y_test_one_hot = encoder.fit_transform(y_test.reshape(-1, 1))\n",
    "                y_forget_one_hot = encoder.transform(y_forget.reshape(-1, 1))\n",
    "\n",
    "                loss_test = np.array([metrics.log_loss(y_test_one_hot[i], test_preds[i]) for i in range(len(y_test))])\n",
    "                loss_forget = np.array([metrics.log_loss(y_forget_one_hot[i], forget_preds[i]) for i in range(len(y_forget))])\n",
    "\n",
    "                attack_result = tf_attack(logits_train = forget_preds, logits_test = test_preds[rand_idxs], \n",
    "                                          loss_train = loss_forget, loss_test = loss_test[rand_idxs], \n",
    "                                          train_labels = y_forget, test_labels = y_test[rand_idxs])\n",
    "\n",
    "                auc = attack_result.get_result_with_max_auc().get_auc()\n",
    "                adv = attack_result.get_result_with_max_attacker_advantage().get_attacker_advantage()\n",
    "                mia_aucs_k_D.append(100.0*auc)\n",
    "                mia_advs_k_D.append(100.0*adv)\n",
    "\n",
    "                model_k_ret = copy.deepcopy(initial_model)\n",
    "                model_k_ret.set_params(learning_rate = 0.5, n_estimators=ft_epochs)\n",
    "                t0 = time.time()\n",
    "                torch.cuda.empty_cache()\n",
    "                model_k_ret.fit(X_retain, y_retain, xgb_model=model_k)\n",
    "                t1 = time.time()\n",
    "                rt = t1-t0\n",
    "                runtimes_train_k_ret.append(rt)\n",
    "                # Evaluate the model accuracy, and MIA\n",
    "                # Accuracy\n",
    "                retain_acc = roc_auc_score(y_retain, model_k_ret.predict_proba(X_retain)[:, 1])\n",
    "                forget_acc = roc_auc_score(y_forget, model_k_ret.predict_proba(X_forget)[:, 1])\n",
    "                test_acc = roc_auc_score(y_test, model_k_ret.predict_proba(X_test)[:, 1])\n",
    "                retain_accs_k_ret.append(100.0*retain_acc)\n",
    "                forget_accs_k_ret.append(100.0*forget_acc)\n",
    "                test_accs_k_ret.append(100.0*test_acc)\n",
    "                #MIA\n",
    "                idxs = np.arange(len(y_test))\n",
    "                random.shuffle(idxs)\n",
    "                rand_idxs = idxs[:m]\n",
    "\n",
    "                test_preds = model_k_ret.predict_proba(X_test)\n",
    "                forget_preds = model_k_ret.predict_proba(X_forget)\n",
    "                loss_test = np.array([metrics.log_loss(y_test_one_hot[i], test_preds[i]) for i in range(len(y_test))])\n",
    "                loss_forget = np.array([metrics.log_loss(y_forget_one_hot[i], forget_preds[i]) for i in range(len(y_forget))])\n",
    "\n",
    "                attack_result = tf_attack(logits_train = forget_preds, logits_test = test_preds[rand_idxs], \n",
    "                                          loss_train = loss_forget, loss_test = loss_test[rand_idxs], \n",
    "                                          train_labels = y_forget, test_labels = y_test[rand_idxs])\n",
    "\n",
    "                auc = attack_result.get_result_with_max_auc().get_auc()\n",
    "                adv = attack_result.get_result_with_max_attacker_advantage().get_attacker_advantage()\n",
    "                mia_aucs_k_ret.append(100.0*auc)\n",
    "                mia_advs_k_ret.append(100.0*adv)\n",
    "\n",
    "\n",
    "            # Anonymizing D and training M_k on D_k\n",
    "            mean_anonymize_time = np.mean(runtimes_k)\n",
    "            std_anonymize_time = np.std(runtimes_k)\n",
    "            mean_train_k_time = np.mean(runtimes_train_k)\n",
    "            std_train_k_time = np.std(runtimes_train_k)\n",
    "            mean_train_k_acc = np.mean(train_accs_k)\n",
    "            std_train_k_acc = np.std(train_accs_k)\n",
    "            mean_test_k_acc = np.mean(test_accs_k)\n",
    "            std_test_k_acc = np.std(test_accs_k)\n",
    "            mean_mia_k_auc = np.mean(mia_aucs_k)\n",
    "            std_mia_k_auc = np.std(mia_aucs_k)\n",
    "            mean_mia_k_adv = np.mean(mia_advs_k)\n",
    "            std_mia_k_adv = np.std(mia_advs_k)\n",
    "\n",
    "            # Finetuning M_k on D\n",
    "            mean_finetune_D_time = np.mean(runtimes_train_k_D)\n",
    "            std_finetune_D_time = np.std(runtimes_train_k_D)\n",
    "            mean_finetune_D_train_acc = np.mean(train_accs_k_D)\n",
    "            std_finetune_D_train_acc = np.std(train_accs_k_D)\n",
    "            mean_finetune_D_test_acc = np.mean(test_accs_k_D)\n",
    "            std_finetune_D_test_acc = np.std(test_accs_k_D)\n",
    "            mean_finetune_D_mia_auc = np.mean(mia_aucs_k_D)\n",
    "            std_finetune_D_mia_auc = np.std(mia_aucs_k_D)\n",
    "            mean_finetune_D_mia_adv = np.mean(mia_advs_k_D)\n",
    "            std_finetune_D_mia_adv = np.std(mia_advs_k_D)\n",
    "\n",
    "            # Finetuning M_k on D_ret\n",
    "            mean_finetune_D_ret_time = np.mean(runtimes_train_k_ret)\n",
    "            std_finetune_D_ret_time = np.std(runtimes_train_k_ret)\n",
    "            mean_finetune_D_ret_train_acc = np.mean(retain_accs_k_ret)\n",
    "            std_finetune_D_ret_train_acc = np.std(retain_accs_k_ret)\n",
    "            mean_finetune_D_ret_forget_acc = np.mean(forget_accs_k_ret)\n",
    "            std_finetune_D_ret_forget_acc = np.std(forget_accs_k_ret)\n",
    "            mean_finetune_D_ret_test_acc = np.mean(test_accs_k_ret)\n",
    "            std_finetune_D_ret_test_acc = np.std(test_accs_k_ret)\n",
    "            mean_finetune_D_ret_mia_auc = np.mean(mia_aucs_k_ret)\n",
    "            std_finetune_D_ret_mia_auc = np.std(mia_aucs_k_ret)\n",
    "            mean_finetune_D_ret_mia_adv = np.mean(mia_advs_k_ret)\n",
    "            std_finetune_D_ret_mia_adv = np.std(mia_advs_k_ret)\n",
    "\n",
    "\n",
    "            # Print the results\n",
    "            print('----------------------------------------')\n",
    "            print('k=', k, 'Fine-tuning epochs=', ft_epochs)\n",
    "            print('----------------------------------------')\n",
    "            print('-----Anonymizing D and training M_k on D_k-----')\n",
    "            print('Anonymizing D time:{:0.2f}(±{:0.2f})'.format(mean_anonymize_time, std_anonymize_time))\n",
    "            print('Training M_k on D_k time:{:0.2f}(±{:0.2f})'.format(mean_train_k_time, std_train_k_time))\n",
    "            print('Train AUC:{:0.2f}(±{:0.2f})%'.format(mean_train_k_acc, std_train_k_acc))\n",
    "            print('Test AUC:{:0.2f}(±{:0.2f})%'.format(mean_test_k_acc, std_test_k_acc))\n",
    "            print('MIA AUC:{:0.2f}(±{:0.2f})%'.format(mean_mia_k_auc, std_mia_k_auc))\n",
    "            print('MIA Advantage:{:0.2f}(±{:0.2f})%'.format(mean_mia_k_adv, std_mia_k_adv))\n",
    "\n",
    "            print('-----Finetuning M_k on D-----')\n",
    "            print('Training M_k on D time:{:0.2f}(±{:0.2f})'.format(mean_finetune_D_time, std_finetune_D_time))\n",
    "            print('Train AUC:{:0.2f}(±{:0.2f})%'.format(mean_finetune_D_train_acc, std_finetune_D_train_acc))\n",
    "            print('Test AUC:{:0.2f}(±{:0.2f})%'.format(mean_finetune_D_test_acc, std_finetune_D_test_acc))\n",
    "            print('MIA AUC:{:0.2f}(±{:0.2f})%'.format(mean_finetune_D_mia_auc, std_finetune_D_mia_auc))\n",
    "            print('MIA Advantage:{:0.2f}(±{:0.2f})%'.format(mean_finetune_D_mia_adv, std_finetune_D_mia_adv))\n",
    "\n",
    "            print('-----Finetuning M_k on D_ret-----')\n",
    "            print('Finetuning M_k on D_retain time:{:0.2f}(±{:0.2f}) seconds'.format(mean_finetune_D_ret_time, std_finetune_D_ret_time))\n",
    "            print('Retain AUC:{:0.2f}(±{:0.2f})%'.format(mean_finetune_D_ret_train_acc, std_finetune_D_ret_train_acc))\n",
    "            print('Forget AUC:{:0.2f}(±{:0.2f})%'.format(mean_finetune_D_ret_forget_acc, std_finetune_D_ret_forget_acc))\n",
    "            print('Test AUC:{:0.2f}(±{:0.2f})%'.format(mean_finetune_D_ret_test_acc, std_finetune_D_ret_test_acc))\n",
    "            print('MIA AUC:{:0.2f}(±{:0.2f})%'.format(mean_finetune_D_ret_mia_auc, std_finetune_D_ret_mia_auc))\n",
    "            print('MIA Advantage:{:0.2f}(±{:0.2f})%'.format(mean_finetune_D_ret_mia_adv, std_finetune_D_ret_mia_adv))\n",
    "            print('----------------------------------------')\n",
    "\n",
    "            # Save to CSV\n",
    "            csv_anonymize_file_path = 'results/credit/xgb_mk={}_dk_fr={}.csv'.format(k, forget_ratio)\n",
    "            csv_finetune_D_file_path = 'results/credit/xgb_mk={}_d_fr={}_epochs={}.csv'.format(k, forget_ratio, ft_epochs)\n",
    "            csv_finetune_D_ret_file_path = 'results/credit/xgb_mk={}_dret_fr={}_epochs={}.csv'.format(k, forget_ratio, ft_epochs)\n",
    "\n",
    "            # Writing to CSV for anonymizing, finetuning on D, and finetuning on D_ret\n",
    "            with open(csv_anonymize_file_path, mode='w', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(['Metric', 'Mean', 'Standard Deviation'])\n",
    "                writer.writerow(['Anonymizing Time', mean_anonymize_time, std_anonymize_time])\n",
    "                writer.writerow(['Training M_k on D_k Time', mean_train_k_time, std_train_k_time])\n",
    "                writer.writerow(['Train AUC', mean_train_k_acc, std_train_k_acc])\n",
    "                writer.writerow(['Test AUC', mean_test_k_acc, std_test_k_acc])\n",
    "                writer.writerow(['MIA AUC', mean_mia_k_auc, std_mia_k_auc])\n",
    "                writer.writerow(['MIA Advantage', mean_mia_k_adv, std_mia_k_adv])\n",
    "\n",
    "            with open(csv_finetune_D_file_path, mode='w', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(['Metric', 'Mean', 'Standard Deviation'])\n",
    "                writer.writerow(['Training M_k on D Time', mean_finetune_D_time, std_finetune_D_time])\n",
    "                writer.writerow(['Train AUC', mean_finetune_D_train_acc, std_finetune_D_train_acc])\n",
    "                writer.writerow(['Test AUC', mean_finetune_D_test_acc, std_finetune_D_test_acc])\n",
    "                writer.writerow(['MIA AUC', mean_finetune_D_mia_auc, std_finetune_D_mia_auc])\n",
    "                writer.writerow(['MIA Advantage', mean_finetune_D_mia_adv, std_finetune_D_mia_adv])\n",
    "\n",
    "            with open(csv_finetune_D_ret_file_path, mode='w', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(['Metric', 'Mean', 'Standard Deviation'])\n",
    "                writer.writerow(['Finetuning M_k on D_retain Time', mean_finetune_D_ret_time, std_finetune_D_ret_time])\n",
    "                writer.writerow(['Retain AUC', mean_finetune_D_ret_train_acc, std_finetune_D_ret_train_acc])\n",
    "                writer.writerow(['Forget AUC', mean_finetune_D_ret_forget_acc, std_finetune_D_ret_forget_acc])\n",
    "                writer.writerow(['Test AUC', mean_finetune_D_ret_test_acc, std_finetune_D_ret_test_acc])\n",
    "                writer.writerow(['MIA AUC', mean_finetune_D_ret_mia_auc, std_finetune_D_ret_mia_auc])\n",
    "                writer.writerow(['MIA Advantage', mean_finetune_D_ret_mia_adv, std_finetune_D_ret_mia_adv])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac39efc",
   "metadata": {},
   "source": [
    "# Differential privacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f5d47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly sample retain and forget sets\n",
    "forget_ratios = [0.05, 0.2, 0.5]\n",
    "# Step 1: k-anonymize and prepare D_k\n",
    "ft_epochs_list = [5]\n",
    "m = int(len(y_train)*forget_ratio)\n",
    "idxs = np.arange(len(y_train))\n",
    "random.shuffle(idxs)\n",
    "\n",
    "retain_idxs = idxs[m:]\n",
    "forget_idxs = idxs[:m]\n",
    "X_retain = X_train[retain_idxs]\n",
    "y_retain = y_train[retain_idxs]\n",
    "X_forget = X_train[forget_idxs]\n",
    "y_forget = y_train[forget_idxs]\n",
    "\n",
    "for forget_ratio in forget_ratios:\n",
    "    idxs = np.arange(len(y_train))\n",
    "    random.shuffle(idxs)\n",
    "    m = int(len(y_train)*forget_ratio)\n",
    "    retain_idxs = idxs[m:]\n",
    "    forget_idxs = idxs[:m]\n",
    "    X_retain = X_train[retain_idxs]\n",
    "    y_retain = y_train[retain_idxs]\n",
    "    X_forget = X_train[forget_idxs]\n",
    "    y_forget = y_train[forget_idxs]\n",
    "\n",
    "    for r in range(n_repeat):\n",
    "        ft_epochs_list = [5]\n",
    "        for ft_epochs in ft_epochs_list:\n",
    "            EPS = [0.5]\n",
    "            for eps in EPS:\n",
    "                dp_train_data = pd.read_csv('dp_data/GiveMeSomeCredit/dp_credit_eps={}.csv'.format(eps), sep=',')\n",
    "                # Drop useless columns\n",
    "                dp_train_data.dropna(inplace=True)\n",
    "                # convert the income column to 0 or 1 and then drop the column for the feature vectors\n",
    "                # creating the feature vector \n",
    "                X_train_dp = dp_train_data.drop('SeriousDlqin2yrs', axis =1)\n",
    "                # target values\n",
    "                y_train_dp = dp_train_data['SeriousDlqin2yrs'].values\n",
    "                # pass the data through the full_pipeline\n",
    "                X_train_dp = SC.fit_transform(X_train_dp)\n",
    "                print(forget_ratio, ft_epochs, eps, X_train_dp.shape, y_train_dp.shape)\n",
    "                train_accs_k = []\n",
    "                test_accs_k = []\n",
    "                mia_aucs_k = []\n",
    "                mia_advs_k = []\n",
    "                runtimes_train_k = []\n",
    "\n",
    "                train_accs_k_D = []\n",
    "                test_accs_k_D = []\n",
    "                mia_aucs_k_D = []\n",
    "                mia_advs_k_D = []\n",
    "                runtimes_train_k_D = []\n",
    "\n",
    "                retain_accs_k_ret = []\n",
    "                forget_accs_k_ret = []\n",
    "                test_accs_k_ret = []\n",
    "                mia_aucs_k_ret = []\n",
    "                mia_advs_k_ret = []\n",
    "                runtimes_train_k_ret = []\n",
    "\n",
    "                for r in range(n_repeat):\n",
    "                    model_k = copy.deepcopy(initial_model)\n",
    "                    t0 = time.time()\n",
    "                    torch.cuda.empty_cache()\n",
    "                    model_k.fit(X_train_dp, y_train_dp)\n",
    "                    t1 = time.time()\n",
    "                    rt_train = t1- t0\n",
    "                    runtimes_train_k.append(rt_train)\n",
    "\n",
    "                    # Evaluate the model accuracy, and MIA\n",
    "                    # Accuracy\n",
    "                    train_acc = roc_auc_score(y_train_dp, model_k.predict_proba(X_train_dp)[:, 1])\n",
    "                    test_acc = roc_auc_score(y_test, model_k.predict_proba(X_test)[:, 1])\n",
    "                    train_accs_k.append(100.0*train_acc)\n",
    "                    test_accs_k.append(100.0*test_acc)\n",
    "                    #MIA\n",
    "                    idxs = np.arange(len(y_test))\n",
    "                    random.shuffle(idxs)\n",
    "                    rand_idxs = idxs[:m]\n",
    "\n",
    "                    test_preds = model_k.predict_proba(X_test)\n",
    "                    forget_preds = model_k.predict_proba(X_forget)\n",
    "\n",
    "                    # Convert class indices to one-hot encoding\n",
    "                    y_test_one_hot = encoder.fit_transform(y_test.reshape(-1, 1))\n",
    "                    y_forget_one_hot = encoder.transform(y_forget.reshape(-1, 1))\n",
    "\n",
    "                    loss_test = np.array([metrics.log_loss(y_test_one_hot[i], test_preds[i]) for i in range(len(y_test))])\n",
    "                    loss_forget = np.array([metrics.log_loss(y_forget_one_hot[i], forget_preds[i]) for i in range(len(y_forget))])\n",
    "\n",
    "                    attack_result = tf_attack(logits_train = forget_preds, logits_test = test_preds[rand_idxs], \n",
    "                                              loss_train = loss_forget, loss_test = loss_test[rand_idxs], \n",
    "                                              train_labels = y_forget, test_labels = y_test[rand_idxs])\n",
    "\n",
    "                    auc = attack_result.get_result_with_max_auc().get_auc()\n",
    "                    adv = attack_result.get_result_with_max_attacker_advantage().get_attacker_advantage()\n",
    "                    mia_aucs_k.append(100.0*auc)\n",
    "                    mia_advs_k.append(100.0*adv)\n",
    "\n",
    "                    model_k_D = copy.deepcopy(initial_model)\n",
    "                    model_k_D.set_params(learning_rate = 0.5, n_estimators=ft_epochs)\n",
    "                    t0 = time.time()\n",
    "                    torch.cuda.empty_cache()\n",
    "                    model_k_D.fit(X_train, y_train, xgb_model=model_k)\n",
    "                    t1 = time.time()\n",
    "                    rt = t1-t0\n",
    "                    runtimes_train_k_D.append(rt)\n",
    "\n",
    "                    # Evaluate the model accuracy, and MIA\n",
    "                    # Accuracy\n",
    "                    train_acc = roc_auc_score(y_train, model_k_D.predict_proba(X_train)[:, 1])\n",
    "                    test_acc = roc_auc_score(y_test, model_k_D.predict_proba(X_test)[:, 1])\n",
    "                    train_accs_k_D.append(100.0*train_acc)\n",
    "                    test_accs_k_D.append(100.0*test_acc)\n",
    "                    #MIA\n",
    "                    idxs = np.arange(len(y_test))\n",
    "                    random.shuffle(idxs)\n",
    "                    rand_idxs = idxs[:m]\n",
    "\n",
    "                    test_preds = model_k_D.predict_proba(X_test)\n",
    "                    forget_preds = model_k_D.predict_proba(X_forget)\n",
    "\n",
    "                    # Convert class indices to one-hot encoding\n",
    "                    y_test_one_hot = encoder.fit_transform(y_test.reshape(-1, 1))\n",
    "                    y_forget_one_hot = encoder.transform(y_forget.reshape(-1, 1))\n",
    "\n",
    "                    loss_test = np.array([metrics.log_loss(y_test_one_hot[i], test_preds[i]) for i in range(len(y_test))])\n",
    "                    loss_forget = np.array([metrics.log_loss(y_forget_one_hot[i], forget_preds[i]) for i in range(len(y_forget))])\n",
    "\n",
    "                    attack_result = tf_attack(logits_train = forget_preds, logits_test = test_preds[rand_idxs], \n",
    "                                              loss_train = loss_forget, loss_test = loss_test[rand_idxs], \n",
    "                                              train_labels = y_forget, test_labels = y_test[rand_idxs])\n",
    "\n",
    "                    auc = attack_result.get_result_with_max_auc().get_auc()\n",
    "                    adv = attack_result.get_result_with_max_attacker_advantage().get_attacker_advantage()\n",
    "                    mia_aucs_k_D.append(100.0*auc)\n",
    "                    mia_advs_k_D.append(100.0*adv)\n",
    "\n",
    "                    model_k_ret = copy.deepcopy(initial_model)\n",
    "                    model_k_ret.set_params(learning_rate = 0.5, n_estimators=ft_epochs)\n",
    "                    t0 = time.time()\n",
    "                    torch.cuda.empty_cache()\n",
    "                    model_k_ret.fit(X_retain, y_retain, xgb_model=model_k)\n",
    "                    t1 = time.time()\n",
    "                    rt = t1-t0\n",
    "                    runtimes_train_k_ret.append(rt)\n",
    "                    # Evaluate the model accuracy, and MIA\n",
    "                    # Accuracy\n",
    "                    retain_acc = roc_auc_score(y_retain, model_k_ret.predict_proba(X_retain)[:, 1])\n",
    "                    forget_acc = roc_auc_score(y_forget, model_k_ret.predict_proba(X_forget)[:, 1])\n",
    "                    test_acc = roc_auc_score(y_test, model_k_ret.predict_proba(X_test)[:, 1])\n",
    "                    retain_accs_k_ret.append(100.0*retain_acc)\n",
    "                    forget_accs_k_ret.append(100.0*forget_acc)\n",
    "                    test_accs_k_ret.append(100.0*test_acc)\n",
    "                    #MIA\n",
    "                    idxs = np.arange(len(y_test))\n",
    "                    random.shuffle(idxs)\n",
    "                    rand_idxs = idxs[:m]\n",
    "\n",
    "                    test_preds = model_k_ret.predict_proba(X_test)\n",
    "                    forget_preds = model_k_ret.predict_proba(X_forget)\n",
    "                    loss_test = np.array([metrics.log_loss(y_test_one_hot[i], test_preds[i]) for i in range(len(y_test))])\n",
    "                    loss_forget = np.array([metrics.log_loss(y_forget_one_hot[i], forget_preds[i]) for i in range(len(y_forget))])\n",
    "\n",
    "                    attack_result = tf_attack(logits_train = forget_preds, logits_test = test_preds[rand_idxs], \n",
    "                                              loss_train = loss_forget, loss_test = loss_test[rand_idxs], \n",
    "                                              train_labels = y_forget, test_labels = y_test[rand_idxs])\n",
    "\n",
    "                    auc = attack_result.get_result_with_max_auc().get_auc()\n",
    "                    adv = attack_result.get_result_with_max_attacker_advantage().get_attacker_advantage()\n",
    "                    mia_aucs_k_ret.append(100.0*auc)\n",
    "                    mia_advs_k_ret.append(100.0*adv)\n",
    "\n",
    "\n",
    "                # Anonymizing D and training M_k on D_k\n",
    "                mean_train_k_time = np.mean(runtimes_train_k)\n",
    "                std_train_k_time = np.std(runtimes_train_k)\n",
    "                mean_train_k_acc = np.mean(train_accs_k)\n",
    "                std_train_k_acc = np.std(train_accs_k)\n",
    "                mean_test_k_acc = np.mean(test_accs_k)\n",
    "                std_test_k_acc = np.std(test_accs_k)\n",
    "                mean_mia_k_auc = np.mean(mia_aucs_k)\n",
    "                std_mia_k_auc = np.std(mia_aucs_k)\n",
    "                mean_mia_k_adv = np.mean(mia_advs_k)\n",
    "                std_mia_k_adv = np.std(mia_advs_k)\n",
    "\n",
    "                # Finetuning M_k on D\n",
    "                mean_finetune_D_time = np.mean(runtimes_train_k_D)\n",
    "                std_finetune_D_time = np.std(runtimes_train_k_D)\n",
    "                mean_finetune_D_train_acc = np.mean(train_accs_k_D)\n",
    "                std_finetune_D_train_acc = np.std(train_accs_k_D)\n",
    "                mean_finetune_D_test_acc = np.mean(test_accs_k_D)\n",
    "                std_finetune_D_test_acc = np.std(test_accs_k_D)\n",
    "                mean_finetune_D_mia_auc = np.mean(mia_aucs_k_D)\n",
    "                std_finetune_D_mia_auc = np.std(mia_aucs_k_D)\n",
    "                mean_finetune_D_mia_adv = np.mean(mia_advs_k_D)\n",
    "                std_finetune_D_mia_adv = np.std(mia_advs_k_D)\n",
    "\n",
    "                # Finetuning M_k on D_ret\n",
    "                mean_finetune_D_ret_time = np.mean(runtimes_train_k_ret)\n",
    "                std_finetune_D_ret_time = np.std(runtimes_train_k_ret)\n",
    "                mean_finetune_D_ret_train_acc = np.mean(retain_accs_k_ret)\n",
    "                std_finetune_D_ret_train_acc = np.std(retain_accs_k_ret)\n",
    "                mean_finetune_D_ret_forget_acc = np.mean(forget_accs_k_ret)\n",
    "                std_finetune_D_ret_forget_acc = np.std(forget_accs_k_ret)\n",
    "                mean_finetune_D_ret_test_acc = np.mean(test_accs_k_ret)\n",
    "                std_finetune_D_ret_test_acc = np.std(test_accs_k_ret)\n",
    "                mean_finetune_D_ret_mia_auc = np.mean(mia_aucs_k_ret)\n",
    "                std_finetune_D_ret_mia_auc = np.std(mia_aucs_k_ret)\n",
    "                mean_finetune_D_ret_mia_adv = np.mean(mia_advs_k_ret)\n",
    "                std_finetune_D_ret_mia_adv = np.std(mia_advs_k_ret)\n",
    "\n",
    "\n",
    "                # Print the results\n",
    "                print('----------------------------------------')\n",
    "                print('Epsilon=', eps, 'Fine-tuning epochs=', ft_epochs)\n",
    "                print('----------------------------------------')\n",
    "                print('-----Anonymizing D and training M_k on D_k-----')\n",
    "                print('Training M_k on D_k time:{:0.2f}(±{:0.2f})'.format(mean_train_k_time, std_train_k_time))\n",
    "                print('Train accuracy:{:0.2f}(±{:0.2f})%'.format(mean_train_k_acc, std_train_k_acc))\n",
    "                print('Test accuracy:{:0.2f}(±{:0.2f})%'.format(mean_test_k_acc, std_test_k_acc))\n",
    "                print('MIA AUC:{:0.2f}(±{:0.2f})%'.format(mean_mia_k_auc, std_mia_k_auc))\n",
    "                print('MIA Advantage:{:0.2f}(±{:0.2f})%'.format(mean_mia_k_adv, std_mia_k_adv))\n",
    "\n",
    "                print('-----Finetuning M_k on D-----')\n",
    "                print('Training M_k on D time:{:0.2f}(±{:0.2f})'.format(mean_finetune_D_time, std_finetune_D_time))\n",
    "                print('Train accuracy:{:0.2f}(±{:0.2f})%'.format(mean_finetune_D_train_acc, std_finetune_D_train_acc))\n",
    "                print('Test accuracy:{:0.2f}(±{:0.2f})%'.format(mean_finetune_D_test_acc, std_finetune_D_test_acc))\n",
    "                print('MIA AUC:{:0.2f}(±{:0.2f})%'.format(mean_finetune_D_mia_auc, std_finetune_D_mia_auc))\n",
    "                print('MIA Advantage:{:0.2f}(±{:0.2f})%'.format(mean_finetune_D_mia_adv, std_finetune_D_mia_adv))\n",
    "\n",
    "                print('-----Finetuning M_k on D_ret-----')\n",
    "                print('Finetuning M_k on D_retain time:{:0.2f}(±{:0.2f}) seconds'.format(mean_finetune_D_ret_time, std_finetune_D_ret_time))\n",
    "                print('Retain accuracy:{:0.2f}(±{:0.2f})%'.format(mean_finetune_D_ret_train_acc, std_finetune_D_ret_train_acc))\n",
    "                print('Forget accuracy:{:0.2f}(±{:0.2f})%'.format(mean_finetune_D_ret_forget_acc, std_finetune_D_ret_forget_acc))\n",
    "                print('Test accuracy:{:0.2f}(±{:0.2f})%'.format(mean_finetune_D_ret_test_acc, std_finetune_D_ret_test_acc))\n",
    "                print('MIA AUC:{:0.2f}(±{:0.2f})%'.format(mean_finetune_D_ret_mia_auc, std_finetune_D_ret_mia_auc))\n",
    "                print('MIA Advantage:{:0.2f}(±{:0.2f})%'.format(mean_finetune_D_ret_mia_adv, std_finetune_D_ret_mia_adv))\n",
    "                print('----------------------------------------')\n",
    "\n",
    "                # Save to CSV\n",
    "                csv_anonymize_file_path = 'results/credit/xgb_mdp_eps={}_fr={}.csv'.format(eps, forget_ratio)\n",
    "                csv_finetune_D_file_path = 'results/credit/xgb_mdpd_eps={}_fr={}_epochs={}.csv'.format(eps, forget_ratio, ft_epochs)\n",
    "                csv_finetune_D_ret_file_path = 'results/credit/xgb_mdpret_eps={}_fr={}_epochs={}.csv'.format(eps, forget_ratio, ft_epochs)\n",
    "\n",
    "                # Writing to CSV for anonymizing, finetuning on D, and finetuning on D_ret\n",
    "                with open(csv_anonymize_file_path, mode='w', newline='') as file:\n",
    "                    writer = csv.writer(file)\n",
    "                    writer.writerow(['Metric', 'Mean', 'Standard Deviation'])\n",
    "                    writer.writerow(['Training M_k on D_k Time', mean_train_k_time, std_train_k_time])\n",
    "                    writer.writerow(['Train AUC', mean_train_k_acc, std_train_k_acc])\n",
    "                    writer.writerow(['Test AUC', mean_test_k_acc, std_test_k_acc])\n",
    "                    writer.writerow(['MIA AUC', mean_mia_k_auc, std_mia_k_auc])\n",
    "                    writer.writerow(['MIA Advantage', mean_mia_k_adv, std_mia_k_adv])\n",
    "\n",
    "                with open(csv_finetune_D_file_path, mode='w', newline='') as file:\n",
    "                    writer = csv.writer(file)\n",
    "                    writer.writerow(['Metric', 'Mean', 'Standard Deviation'])\n",
    "                    writer.writerow(['Training M_k on D Time', mean_finetune_D_time, std_finetune_D_time])\n",
    "                    writer.writerow(['Train AUC', mean_finetune_D_train_acc, std_finetune_D_train_acc])\n",
    "                    writer.writerow(['Test AUC', mean_finetune_D_test_acc, std_finetune_D_test_acc])\n",
    "                    writer.writerow(['MIA AUC', mean_finetune_D_mia_auc, std_finetune_D_mia_auc])\n",
    "                    writer.writerow(['MIA Advantage', mean_finetune_D_mia_adv, std_finetune_D_mia_adv])\n",
    "\n",
    "                with open(csv_finetune_D_ret_file_path, mode='w', newline='') as file:\n",
    "                    writer = csv.writer(file)\n",
    "                    writer.writerow(['Metric', 'Mean', 'Standard Deviation'])\n",
    "                    writer.writerow(['Finetuning M_k on D_retain Time', mean_finetune_D_ret_time, std_finetune_D_ret_time])\n",
    "                    writer.writerow(['Retain AUC', mean_finetune_D_ret_train_acc, std_finetune_D_ret_train_acc])\n",
    "                    writer.writerow(['Forget AUC', mean_finetune_D_ret_forget_acc, std_finetune_D_ret_forget_acc])\n",
    "                    writer.writerow(['Test AUC', mean_finetune_D_ret_test_acc, std_finetune_D_ret_test_acc])\n",
    "                    writer.writerow(['MIA AUC', mean_finetune_D_ret_mia_auc, std_finetune_D_ret_mia_auc])\n",
    "                    writer.writerow(['MIA Advantage', mean_finetune_D_ret_mia_adv, std_finetune_D_ret_mia_adv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a298f63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
