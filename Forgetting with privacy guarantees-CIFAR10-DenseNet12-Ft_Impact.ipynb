{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d3343a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from datasets import *\n",
    "from mdav import *\n",
    "from train import *\n",
    "from models import *\n",
    "from attacks import *\n",
    "from dp_data.load_dp_cifar10_dataset import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import dataset, DataLoader, TensorDataset, Subset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import random\n",
    "import time\n",
    "import copy\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import scipy\n",
    "import csv\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee76b2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning, FitFailedWarning\n",
    "\n",
    "# Filter out ConvergenceWarning and FitFailedWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FitFailedWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd6937e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=7):\n",
    "    np.random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba412321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Class=6, Count=5000, Percentage=10.00%\n",
      "Class=9, Count=5000, Percentage=10.00%\n",
      "Class=4, Count=5000, Percentage=10.00%\n",
      "Class=1, Count=5000, Percentage=10.00%\n",
      "Class=2, Count=5000, Percentage=10.00%\n",
      "Class=7, Count=5000, Percentage=10.00%\n",
      "Class=8, Count=5000, Percentage=10.00%\n",
      "Class=3, Count=5000, Percentage=10.00%\n",
      "Class=5, Count=5000, Percentage=10.00%\n",
      "Class=0, Count=5000, Percentage=10.00%\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "\n",
    "transform_train = transforms.Compose([  \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "num_classes = 10\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "# Randomly sample retain and forget sets\n",
    "y_train = trainset.targets\n",
    "forget_ratio = 0.05\n",
    "idxs = np.arange(len(y_train))\n",
    "random.shuffle(idxs)\n",
    "\n",
    "m = int(len(trainset) * forget_ratio)  # Number of samples to forget\n",
    "retain_idxs = idxs[m:]  # Indices for the retain set\n",
    "forget_idxs = idxs[:m]  # Indices for the forget set\n",
    "\n",
    "# Split the data based on indices\n",
    "retain_set = Subset(trainset, retain_idxs)\n",
    "forget_set = Subset(trainset, forget_idxs)\n",
    "\n",
    "# Create DataLoader instances\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
    "retain_loader = DataLoader(retain_set, batch_size=batch_size, shuffle=True)\n",
    "forget_loader = DataLoader(forget_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "counter = Counter(y_train)\n",
    "for k,v in counter.items():\n",
    "    per = v / len(y_train) * 100\n",
    "    print('Class=%s, Count=%d, Percentage=%.2f%%' % (k, v, per))\n",
    "    \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "initial_model = densenet(num_classes=num_classes,depth=100,growthRate=12,compressionRate=2,dropRate=0)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 0.1\n",
    "n_repeat = 1\n",
    "max_epochs = 100\n",
    "patience = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863c035b",
   "metadata": {},
   "source": [
    "# Differential privacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0552ff6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:45<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100] | Train Loss: 2.316596520831213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:44<00:00,  2.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:43<00:00,  2.76it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:42<00:00,  2.76it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:44<00:00,  2.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:45<00:00,  2.74it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:44<00:00,  2.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:45<00:00,  2.74it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:44<00:00,  2.74it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:43<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100] | Train Loss: 2.211079520337722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:45<00:00,  2.74it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:44<00:00,  2.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:43<00:00,  2.76it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:44<00:00,  2.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:44<00:00,  2.74it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:44<00:00,  2.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:44<00:00,  2.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:45<00:00,  2.74it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:44<00:00,  2.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:44<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/100] | Train Loss: 1.9685819537743279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:45<00:00,  2.74it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:44<00:00,  2.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:44<00:00,  2.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:44<00:00,  2.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:44<00:00,  2.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:44<00:00,  2.74it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:44<00:00,  2.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:44<00:00,  2.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:44<00:00,  2.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:45<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/100] | Train Loss: 1.3769919676396547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:44<00:00,  2.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:45<00:00,  2.74it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:45<00:00,  2.74it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:43<00:00,  2.76it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:45<00:00,  2.74it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:45<00:00,  2.74it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:43<00:00,  2.76it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:44<00:00,  2.74it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:45<00:00,  2.73it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:47<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/100] | Train Loss: 0.6988035480460852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:44<00:00,  2.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:45<00:00,  2.74it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:44<00:00,  2.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:43<00:00,  2.76it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:44<00:00,  2.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:45<00:00,  2.74it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:44<00:00,  2.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:44<00:00,  2.74it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:44<00:00,  2.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:43<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/100] | Train Loss: 0.2310362083127584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:45<00:00,  2.74it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:44<00:00,  2.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:42<00:00,  2.76it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:44<00:00,  2.74it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:45<00:00,  2.74it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:43<00:00,  2.76it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:45<00:00,  2.74it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:45<00:00,  2.74it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:44<00:00,  2.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:44<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/100] | Train Loss: 0.008310830690781883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:44<00:00,  2.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:43<00:00,  2.76it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:44<00:00,  2.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:43<00:00,  2.76it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:44<00:00,  2.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:44<00:00,  2.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:43<00:00,  2.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:44<00:00,  2.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:44<00:00,  2.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:44<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [70/100] | Train Loss: 0.000746716454178077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:45<00:00,  2.74it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:44<00:00,  2.74it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:44<00:00,  2.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:43<00:00,  2.76it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:44<00:00,  2.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:44<00:00,  2.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:42<00:00,  2.76it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:44<00:00,  2.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:45<00:00,  2.74it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:43<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [80/100] | Train Loss: 0.00067559349831626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:44<00:00,  2.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:45<00:00,  2.74it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:43<00:00,  2.76it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:44<00:00,  2.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:44<00:00,  2.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:43<00:00,  2.76it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:44<00:00,  2.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:44<00:00,  2.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:43<00:00,  2.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:44<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [90/100] | Train Loss: 0.001074265962166776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:44<00:00,  2.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:44<00:00,  2.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:43<00:00,  2.76it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:45<00:00,  2.74it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:42<00:00,  2.77it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:43<00:00,  2.76it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:45<00:00,  2.74it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:45<00:00,  2.74it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:44<00:00,  2.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [04:46<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100] | Train Loss: 0.0004720146156000563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [05:29<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] | Train Loss: 1.9247196376171258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [05:28<00:00,  2.38it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [05:28<00:00,  2.38it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [05:28<00:00,  2.38it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [05:28<00:00,  2.38it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [05:28<00:00,  2.38it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [05:28<00:00,  2.38it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [05:30<00:00,  2.37it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [05:29<00:00,  2.37it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [05:30<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.026031287614782544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 743/743 [05:13<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] | Train Loss: 1.8002656592334423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 743/743 [05:14<00:00,  2.37it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 743/743 [05:14<00:00,  2.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 743/743 [05:15<00:00,  2.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 743/743 [05:16<00:00,  2.35it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 743/743 [05:15<00:00,  2.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 743/743 [05:13<00:00,  2.37it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 743/743 [05:14<00:00,  2.37it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 743/743 [05:13<00:00,  2.37it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 743/743 [05:14<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.018573964321747682\n",
      "----------------------------------------\n",
      "Epsilon= 0.5 Fine-tuning epochs= 10\n",
      "----------------------------------------\n",
      "-----Anonymizing D and training M_dp on D_dp-----\n",
      "Training M_k on D_k time:28451.27(±0.00)\n",
      "Train accuracy:13.89(±0.00)%\n",
      "Test accuracy:14.17(±0.00)%\n",
      "MIA AUC:50.54(±0.00)%\n",
      "MIA Advantage:2.72(±0.00)%\n",
      "-----Finetuning M_k on D-----\n",
      "Training M_k on D time:3291.78(±0.00)\n",
      "Train accuracy:99.95(±0.00)%\n",
      "Test accuracy:86.59(±0.00)%\n",
      "MIA AUC:64.68(±0.00)%\n",
      "MIA Advantage:24.24(±0.00)%\n",
      "-----Finetuning M_k on D_ret-----\n",
      "Finetuning M_k on D_retain time:3143.89(±0.00) seconds\n",
      "Retain accuracy:99.97(±0.00)%\n",
      "Forget accuracy:86.12(±0.00)%\n",
      "Test accuracy:85.72(±0.00)%\n",
      "MIA AUC:50.58(±0.00)%\n",
      "MIA Advantage:2.12(±0.00)%\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [05:31<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15] | Train Loss: 1.8488293643802634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [05:30<00:00,  2.37it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [05:29<00:00,  2.37it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [05:31<00:00,  2.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [05:35<00:00,  2.33it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [05:26<00:00,  2.40it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [05:31<00:00,  2.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [05:32<00:00,  2.35it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [05:32<00:00,  2.35it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [05:31<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/15] | Train Loss: 0.09212496657343701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [05:31<00:00,  2.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [05:30<00:00,  2.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [05:31<00:00,  2.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [05:31<00:00,  2.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [05:31<00:00,  2.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 743/743 [05:15<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15] | Train Loss: 1.932969595911044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 743/743 [05:14<00:00,  2.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 743/743 [05:14<00:00,  2.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 743/743 [05:15<00:00,  2.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 743/743 [05:15<00:00,  2.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 743/743 [05:15<00:00,  2.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 743/743 [05:15<00:00,  2.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 743/743 [05:16<00:00,  2.35it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 743/743 [05:15<00:00,  2.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 743/743 [05:16<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/15] | Train Loss: 0.0978338716371163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 743/743 [05:14<00:00,  2.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 743/743 [05:15<00:00,  2.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 743/743 [05:14<00:00,  2.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 743/743 [05:14<00:00,  2.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 743/743 [05:15<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Epsilon= 0.5 Fine-tuning epochs= 15\n",
      "----------------------------------------\n",
      "-----Anonymizing D and training M_dp on D_dp-----\n",
      "Training M_k on D_k time:28451.27(±0.00)\n",
      "Train accuracy:13.89(±0.00)%\n",
      "Test accuracy:14.17(±0.00)%\n",
      "MIA AUC:50.54(±0.00)%\n",
      "MIA Advantage:2.72(±0.00)%\n",
      "-----Finetuning M_k on D-----\n",
      "Training M_k on D time:4968.01(±0.00)\n",
      "Train accuracy:100.00(±0.00)%\n",
      "Test accuracy:87.83(±0.00)%\n",
      "MIA AUC:65.90(±0.00)%\n",
      "MIA Advantage:27.80(±0.00)%\n",
      "-----Finetuning M_k on D_ret-----\n",
      "Finetuning M_k on D_retain time:4727.38(±0.00) seconds\n",
      "Retain accuracy:100.00(±0.00)%\n",
      "Forget accuracy:88.08(±0.00)%\n",
      "Test accuracy:87.12(±0.00)%\n",
      "MIA AUC:50.66(±0.00)%\n",
      "MIA Advantage:2.16(±0.00)%\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [05:31<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] | Train Loss: 1.8659048360174575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [05:30<00:00,  2.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [05:30<00:00,  2.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [05:31<00:00,  2.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [05:30<00:00,  2.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [05:32<00:00,  2.35it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [05:32<00:00,  2.35it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [05:32<00:00,  2.35it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [05:33<00:00,  2.35it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [05:31<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20] | Train Loss: 0.16062276008898568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [05:30<00:00,  2.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [05:32<00:00,  2.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [05:32<00:00,  2.35it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [05:35<00:00,  2.33it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [05:32<00:00,  2.35it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [05:33<00:00,  2.35it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [05:33<00:00,  2.35it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [05:31<00:00,  2.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [05:31<00:00,  2.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [05:31<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20] | Train Loss: 0.0010945159475710762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 743/743 [05:15<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] | Train Loss: 1.7867550566732322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 743/743 [05:15<00:00,  2.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 743/743 [05:13<00:00,  2.37it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 743/743 [05:14<00:00,  2.37it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 743/743 [05:13<00:00,  2.37it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 743/743 [05:14<00:00,  2.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 743/743 [05:13<00:00,  2.37it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 743/743 [05:18<00:00,  2.34it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 743/743 [05:14<00:00,  2.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 743/743 [05:16<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20] | Train Loss: 0.16366729268385535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 743/743 [05:14<00:00,  2.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 743/743 [05:14<00:00,  2.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 743/743 [05:13<00:00,  2.37it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 743/743 [05:13<00:00,  2.37it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 743/743 [05:13<00:00,  2.37it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 743/743 [05:13<00:00,  2.37it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 743/743 [05:13<00:00,  2.37it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 743/743 [05:14<00:00,  2.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 743/743 [05:15<00:00,  2.35it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 743/743 [05:16<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20] | Train Loss: 0.0010829838564777514\n",
      "----------------------------------------\n",
      "Epsilon= 0.5 Fine-tuning epochs= 20\n",
      "----------------------------------------\n",
      "-----Anonymizing D and training M_dp on D_dp-----\n",
      "Training M_k on D_k time:28451.27(±0.00)\n",
      "Train accuracy:13.89(±0.00)%\n",
      "Test accuracy:14.17(±0.00)%\n",
      "MIA AUC:50.54(±0.00)%\n",
      "MIA Advantage:2.72(±0.00)%\n",
      "-----Finetuning M_k on D-----\n",
      "Training M_k on D time:6641.32(±0.00)\n",
      "Train accuracy:100.00(±0.00)%\n",
      "Test accuracy:88.89(±0.00)%\n",
      "MIA AUC:67.04(±0.00)%\n",
      "MIA Advantage:27.32(±0.00)%\n",
      "-----Finetuning M_k on D_ret-----\n",
      "Finetuning M_k on D_retain time:6294.21(±0.00) seconds\n",
      "Retain accuracy:100.00(±0.00)%\n",
      "Forget accuracy:89.20(±0.00)%\n",
      "Test accuracy:88.03(±0.00)%\n",
      "MIA AUC:51.07(±0.00)%\n",
      "MIA Advantage:2.56(±0.00)%\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Step 1: k-anonymize and prepare D_k\n",
    "ft_epochs_list = [10, 15, 20]\n",
    "EPS = [0.5]\n",
    "for epsilon in EPS:\n",
    "    # Directory path for the corresponding epsilon dataset\n",
    "    dataset_dir = f'dp_data/cifar10/m16_b4/dp_cifar10_eps_{epsilon}'\n",
    "\n",
    "    # Use the original CIFAR-10 labels for DP-obfuscated images\n",
    "    labels = trainset.targets\n",
    "    # Create a dataset object for the DP-obfuscated dataset\n",
    "    train_dataset_k = DPCIFAR10Dataset(root_dir=dataset_dir, labels=labels, transform=transform_train)\n",
    "    # Create TensorDatasets\n",
    "    train_loader_k = DataLoader(train_dataset_k, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    train_accs_k = []\n",
    "    test_accs_k = []\n",
    "    mia_aucs_k = []\n",
    "    mia_advs_k = []\n",
    "    runtimes_train_k = []\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    model_k = copy.deepcopy(initial_model)\n",
    "    optimizer = optim.SGD(model_k.parameters(), lr=lr, momentum=0.9)\n",
    "    t0 = time.time()\n",
    "    model_k = train_model(model_k, train_loader_k, test_loader, criterion, optimizer, \n",
    "                    max_epochs, device=device, verbose_epoch = int(max_epochs/10), \n",
    "                    patience = patience)\n",
    "\n",
    "    t1 = time.time()\n",
    "    rt_train = t1- t0\n",
    "    runtimes_train_k.append(rt_train)\n",
    "\n",
    "    # Evaluate the model accuracy, and MIA\n",
    "    model_k.eval()\n",
    "    #Accuracy\n",
    "    train_acc = accuracy(model_k, train_loader)\n",
    "    test_acc = accuracy(model_k, test_loader)\n",
    "    train_accs_k.append(100.0*train_acc)\n",
    "    test_accs_k.append(100.0*test_acc)\n",
    "    #MIA\n",
    "    idxs = np.arange(len(testset))\n",
    "    random.shuffle(idxs)\n",
    "    rand_idxs = idxs[:m]\n",
    "    logits_test, loss_test, test_labels = compute_attack_components(model_k, test_loader)\n",
    "    logits_forget, loss_forget, forget_labels = compute_attack_components(model_k, forget_loader)\n",
    "    attack_result = tf_attack(logits_forget, logits_test[rand_idxs], loss_forget, loss_test[rand_idxs], \n",
    "                          forget_labels, test_labels[rand_idxs])\n",
    "    auc = attack_result.get_result_with_max_auc().get_auc()\n",
    "    adv = attack_result.get_result_with_max_attacker_advantage().get_attacker_advantage()\n",
    "    mia_aucs_k.append(100.0*auc)\n",
    "    mia_advs_k.append(100.0*adv)\n",
    "    \n",
    "    # Further finetune on D and Dr\n",
    "    for ft_epochs in ft_epochs_list:\n",
    "        train_accs_k_D = []\n",
    "        test_accs_k_D = []\n",
    "        mia_aucs_k_D = []\n",
    "        mia_advs_k_D = []\n",
    "        runtimes_train_k_D = []\n",
    "\n",
    "        retain_accs_k_ret = []\n",
    "        forget_accs_k_ret = []\n",
    "        test_accs_k_ret = []\n",
    "        mia_aucs_k_ret = []\n",
    "        mia_advs_k_ret = []\n",
    "        runtimes_train_k_ret = []\n",
    "        \n",
    "        model_k_D = copy.deepcopy(model_k)\n",
    "        torch.cuda.empty_cache()\n",
    "        optimizer = optim.Adam(model_k_D.parameters(), lr=lr/10)\n",
    "        t0 = time.time()\n",
    "        model_k_D = train_model(model_k_D, train_loader, test_loader, criterion, optimizer, \n",
    "                            ft_epochs, device=device, verbose_epoch = int(max_epochs/10), \n",
    "                              patience = patience)\n",
    "\n",
    "        t1 = time.time()\n",
    "        rt = t1-t0\n",
    "        runtimes_train_k_D.append(rt)\n",
    "\n",
    "        # Evaluate the model accuracy, and MIA\n",
    "        model_k_D.eval()\n",
    "        #Accuracy\n",
    "        train_acc = accuracy(model_k_D, train_loader)\n",
    "        test_acc = accuracy(model_k_D, test_loader)\n",
    "        train_accs_k_D.append(100.0*train_acc)\n",
    "        test_accs_k_D.append(100.0*test_acc)\n",
    "        #MIA\n",
    "        logits_test, loss_test, test_labels = compute_attack_components(model_k_D, test_loader)\n",
    "        logits_forget, loss_forget, forget_labels = compute_attack_components(model_k_D, forget_loader)\n",
    "        attack_result = tf_attack(logits_forget, logits_test[rand_idxs], loss_forget, loss_test[rand_idxs], \n",
    "                              forget_labels, test_labels[rand_idxs])\n",
    "        auc = attack_result.get_result_with_max_auc().get_auc()\n",
    "        adv = attack_result.get_result_with_max_attacker_advantage().get_attacker_advantage()\n",
    "        mia_aucs_k_D.append(100.0*auc)\n",
    "        mia_advs_k_D.append(100.0*adv)\n",
    "\n",
    "        model_k_ret = copy.deepcopy(model_k)\n",
    "        torch.cuda.empty_cache()\n",
    "        optimizer = optim.Adam(model_k_ret.parameters(), lr=lr/10)\n",
    "        t0 = time.time()\n",
    "        model_k_ret = train_model(model_k_ret, retain_loader, test_loader, criterion, optimizer, \n",
    "                            ft_epochs, device=device, verbose_epoch = int(max_epochs/10), \n",
    "                              patience = patience)\n",
    "\n",
    "        t1 = time.time()\n",
    "        rt = t1-t0\n",
    "        runtimes_train_k_ret.append(rt)\n",
    "        # Evaluate the model accuracy, and MIA\n",
    "        model_k_ret.eval()\n",
    "        #Accuracy\n",
    "        retain_acc = accuracy(model_k_ret, retain_loader)\n",
    "        forget_acc = accuracy(model_k_ret, forget_loader)\n",
    "        test_acc = accuracy(model_k_ret, test_loader)\n",
    "        retain_accs_k_ret.append(100.0*retain_acc)\n",
    "        forget_accs_k_ret.append(100.0*forget_acc)\n",
    "        test_accs_k_ret.append(100.0*test_acc)\n",
    "        #MIA\n",
    "        logits_test, loss_test, test_labels = compute_attack_components(model_k_ret, test_loader)\n",
    "        logits_forget, loss_forget, forget_labels = compute_attack_components(model_k_ret, forget_loader)\n",
    "        attack_result = tf_attack(logits_forget, logits_test[rand_idxs], loss_forget, loss_test[rand_idxs], \n",
    "                              forget_labels, test_labels[rand_idxs])\n",
    "        auc = attack_result.get_result_with_max_auc().get_auc()\n",
    "        adv = attack_result.get_result_with_max_attacker_advantage().get_attacker_advantage()\n",
    "        mia_aucs_k_ret.append(100.0*auc)\n",
    "        mia_advs_k_ret.append(100.0*adv)\n",
    "\n",
    "        # Anonymizing D and training M_k on D_k\n",
    "        mean_train_k_time = np.mean(runtimes_train_k)\n",
    "        std_train_k_time = np.std(runtimes_train_k)\n",
    "        mean_train_k_acc = np.mean(train_accs_k)\n",
    "        std_train_k_acc = np.std(train_accs_k)\n",
    "        mean_test_k_acc = np.mean(test_accs_k)\n",
    "        std_test_k_acc = np.std(test_accs_k)\n",
    "        mean_mia_k_auc = np.mean(mia_aucs_k)\n",
    "        std_mia_k_auc = np.std(mia_aucs_k)\n",
    "        mean_mia_k_adv = np.mean(mia_advs_k)\n",
    "        std_mia_k_adv = np.std(mia_advs_k)\n",
    "\n",
    "        # Finetuning M_k on D\n",
    "        mean_finetune_D_time = np.mean(runtimes_train_k_D)\n",
    "        std_finetune_D_time = np.std(runtimes_train_k_D)\n",
    "        mean_finetune_D_train_acc = np.mean(train_accs_k_D)\n",
    "        std_finetune_D_train_acc = np.std(train_accs_k_D)\n",
    "        mean_finetune_D_test_acc = np.mean(test_accs_k_D)\n",
    "        std_finetune_D_test_acc = np.std(test_accs_k_D)\n",
    "        mean_finetune_D_mia_auc = np.mean(mia_aucs_k_D)\n",
    "        std_finetune_D_mia_auc = np.std(mia_aucs_k_D)\n",
    "        mean_finetune_D_mia_adv = np.mean(mia_advs_k_D)\n",
    "        std_finetune_D_mia_adv = np.std(mia_advs_k_D)\n",
    "\n",
    "        # Finetuning M_k on D_ret\n",
    "        mean_finetune_D_ret_time = np.mean(runtimes_train_k_ret)\n",
    "        std_finetune_D_ret_time = np.std(runtimes_train_k_ret)\n",
    "        mean_finetune_D_ret_train_acc = np.mean(retain_accs_k_ret)\n",
    "        std_finetune_D_ret_train_acc = np.std(retain_accs_k_ret)\n",
    "        mean_finetune_D_ret_forget_acc = np.mean(forget_accs_k_ret)\n",
    "        std_finetune_D_ret_forget_acc = np.std(forget_accs_k_ret)\n",
    "        mean_finetune_D_ret_test_acc = np.mean(test_accs_k_ret)\n",
    "        std_finetune_D_ret_test_acc = np.std(test_accs_k_ret)\n",
    "        mean_finetune_D_ret_mia_auc = np.mean(mia_aucs_k_ret)\n",
    "        std_finetune_D_ret_mia_auc = np.std(mia_aucs_k_ret)\n",
    "        mean_finetune_D_ret_mia_adv = np.mean(mia_advs_k_ret)\n",
    "        std_finetune_D_ret_mia_adv = np.std(mia_advs_k_ret)\n",
    "\n",
    "        # Print the results\n",
    "        print('----------------------------------------')\n",
    "        print('Epsilon=', epsilon, 'Fine-tuning epochs=', ft_epochs)\n",
    "        print('----------------------------------------')\n",
    "        print('-----Anonymizing D and training M_dp on D_dp-----')\n",
    "        print('Training M_k on D_k time:{:0.2f}(±{:0.2f})'.format(mean_train_k_time, std_train_k_time))\n",
    "        print('Train accuracy:{:0.2f}(±{:0.2f})%'.format(mean_train_k_acc, std_train_k_acc))\n",
    "        print('Test accuracy:{:0.2f}(±{:0.2f})%'.format(mean_test_k_acc, std_test_k_acc))\n",
    "        print('MIA AUC:{:0.2f}(±{:0.2f})%'.format(mean_mia_k_auc, std_mia_k_auc))\n",
    "        print('MIA Advantage:{:0.2f}(±{:0.2f})%'.format(mean_mia_k_adv, std_mia_k_adv))\n",
    "\n",
    "        print('-----Finetuning M_k on D-----')\n",
    "        print('Training M_k on D time:{:0.2f}(±{:0.2f})'.format(mean_finetune_D_time, std_finetune_D_time))\n",
    "        print('Train accuracy:{:0.2f}(±{:0.2f})%'.format(mean_finetune_D_train_acc, std_finetune_D_train_acc))\n",
    "        print('Test accuracy:{:0.2f}(±{:0.2f})%'.format(mean_finetune_D_test_acc, std_finetune_D_test_acc))\n",
    "        print('MIA AUC:{:0.2f}(±{:0.2f})%'.format(mean_finetune_D_mia_auc, std_finetune_D_mia_auc))\n",
    "        print('MIA Advantage:{:0.2f}(±{:0.2f})%'.format(mean_finetune_D_mia_adv, std_finetune_D_mia_adv))\n",
    "\n",
    "        print('-----Finetuning M_k on D_ret-----')\n",
    "        print('Finetuning M_k on D_retain time:{:0.2f}(±{:0.2f}) seconds'.format(mean_finetune_D_ret_time, std_finetune_D_ret_time))\n",
    "        print('Retain accuracy:{:0.2f}(±{:0.2f})%'.format(mean_finetune_D_ret_train_acc, std_finetune_D_ret_train_acc))\n",
    "        print('Forget accuracy:{:0.2f}(±{:0.2f})%'.format(mean_finetune_D_ret_forget_acc, std_finetune_D_ret_forget_acc))\n",
    "        print('Test accuracy:{:0.2f}(±{:0.2f})%'.format(mean_finetune_D_ret_test_acc, std_finetune_D_ret_test_acc))\n",
    "        print('MIA AUC:{:0.2f}(±{:0.2f})%'.format(mean_finetune_D_ret_mia_auc, std_finetune_D_ret_mia_auc))\n",
    "        print('MIA Advantage:{:0.2f}(±{:0.2f})%'.format(mean_finetune_D_ret_mia_adv, std_finetune_D_ret_mia_adv))\n",
    "        print('----------------------------------------')\n",
    "\n",
    "#         # Save to CSV\n",
    "#         csv_anonymize_file_path = 'results/cifar10/densenet12_mdp_eps={}_fr={}.csv'.format(epsilon, forget_ratio)\n",
    "#         csv_finetune_D_file_path = 'results/cifar10/densenet12_mdpd_eps={}_fr={}_epochs={}.csv'.format(epsilon, forget_ratio, ft_epochs)\n",
    "#         csv_finetune_D_ret_file_path = 'results/cifar10/densenet12_mdpret_eps={}_fr={}_epochs={}.csv'.format(epsilon, forget_ratio, ft_epochs)\n",
    "\n",
    "#         # Writing to CSV for anonymizing, finetuning on D, and finetuning on D_ret\n",
    "#         with open(csv_anonymize_file_path, mode='w', newline='') as file:\n",
    "#             writer = csv.writer(file)\n",
    "#             writer.writerow(['Metric', 'Mean', 'Standard Deviation'])\n",
    "#             writer.writerow(['Training M_k on D_k Time', mean_train_k_time, std_train_k_time])\n",
    "#             writer.writerow(['Train Accuracy', mean_train_k_acc, std_train_k_acc])\n",
    "#             writer.writerow(['Test Accuracy', mean_test_k_acc, std_test_k_acc])\n",
    "#             writer.writerow(['MIA AUC', mean_mia_k_auc, std_mia_k_auc])\n",
    "#             writer.writerow(['MIA Advantage', mean_mia_k_adv, std_mia_k_adv])\n",
    "\n",
    "#         with open(csv_finetune_D_file_path, mode='w', newline='') as file:\n",
    "#             writer = csv.writer(file)\n",
    "#             writer.writerow(['Metric', 'Mean', 'Standard Deviation'])\n",
    "#             writer.writerow(['Training M_k on D Time', mean_finetune_D_time, std_finetune_D_time])\n",
    "#             writer.writerow(['Train Accuracy', mean_finetune_D_train_acc, std_finetune_D_train_acc])\n",
    "#             writer.writerow(['Test Accuracy', mean_finetune_D_test_acc, std_finetune_D_test_acc])\n",
    "#             writer.writerow(['MIA AUC', mean_finetune_D_mia_auc, std_finetune_D_mia_auc])\n",
    "#             writer.writerow(['MIA Advantage', mean_finetune_D_mia_adv, std_finetune_D_mia_adv])\n",
    "\n",
    "#         with open(csv_finetune_D_ret_file_path, mode='w', newline='') as file:\n",
    "#             writer = csv.writer(file)\n",
    "#             writer.writerow(['Metric', 'Mean', 'Standard Deviation'])\n",
    "#             writer.writerow(['Finetuning M_k on D_retain Time', mean_finetune_D_ret_time, std_finetune_D_ret_time])\n",
    "#             writer.writerow(['Retain Accuracy', mean_finetune_D_ret_train_acc, std_finetune_D_ret_train_acc])\n",
    "#             writer.writerow(['Forget Accuracy', mean_finetune_D_ret_forget_acc, std_finetune_D_ret_forget_acc])\n",
    "#             writer.writerow(['Test Accuracy', mean_finetune_D_ret_test_acc, std_finetune_D_ret_test_acc])\n",
    "#             writer.writerow(['MIA AUC', mean_finetune_D_ret_mia_auc, std_finetune_D_ret_mia_auc])\n",
    "#             writer.writerow(['MIA Advantage', mean_finetune_D_ret_mia_adv, std_finetune_D_ret_mia_adv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d63d987",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
