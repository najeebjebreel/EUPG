{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d3343a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from datasets import *\n",
    "from mdav import *\n",
    "from train import *\n",
    "from models import *\n",
    "from attacks import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "\n",
    "\n",
    "import random\n",
    "import time\n",
    "import copy\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import scipy\n",
    "import csv\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee76b2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning, FitFailedWarning\n",
    "\n",
    "# Filter out ConvergenceWarning and FitFailedWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FitFailedWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Assuming y_test and y_forget are arrays of class indices\n",
    "encoder = OneHotEncoder(sparse_output=False, categories=\"auto\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd6937e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=7):\n",
    "    np.random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba412321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "columns = [\"age\", \"workClass\", \"fnlwgt\", \"education\", \"education-num\",\n",
    "           \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\", \n",
    "           \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income\"]\n",
    "\n",
    "train_data = pd.read_csv('data/adult/adult.data', names=columns, sep=r' *, *', engine='python', na_values='?')\n",
    "test_data = pd.read_csv('data/adult/adult.test', names=columns, sep=r' *, *', skiprows=1, engine='python', na_values='?')\n",
    "\n",
    "num_pipeline = Pipeline(steps=[\n",
    "    (\"num_attr_selector\", ColumnsSelector(type='int')),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline(steps=[\n",
    "    (\"cat_attr_selector\", ColumnsSelector(type='object')),\n",
    "    (\"cat_imputer\", CategoricalImputer(columns=['workClass','occupation', 'native-country'])),\n",
    "    (\"encoder\", CategoricalEncoder(train_data, test_data, dropFirst=True))\n",
    "])\n",
    "\n",
    "full_pipeline = FeatureUnion([(\"num_pipe\", num_pipeline), (\"cat_pipeline\", cat_pipeline)])\n",
    "\n",
    "# Drop useless columns\n",
    "train_data.drop(['fnlwgt', 'education'], axis=1, inplace=True)\n",
    "train_data.dropna(inplace=True)\n",
    "test_data.drop(['fnlwgt', 'education'], axis=1, inplace=True)\n",
    "test_data.dropna(inplace=True)\n",
    "\n",
    "# copy the data before preprocessing\n",
    "train_copy = train_data.copy()\n",
    "# convert the income column to 0 or 1 and then drop the column for the feature vectors\n",
    "train_copy[\"income\"] = train_copy[\"income\"].apply(lambda x:0 if x=='<=50K' else 1)\n",
    "# creating the feature vector \n",
    "X_train = train_copy.drop('income', axis =1)\n",
    "# target values\n",
    "y_train = train_copy['income'].values\n",
    "# pass the data through the full_pipeline\n",
    "X_train = full_pipeline.fit_transform(X_train)\n",
    "\n",
    "# take a copy of the test data set\n",
    "test_copy = test_data.copy()\n",
    "# convert the income column to 0 or 1\n",
    "test_copy[\"income\"] = test_copy[\"income\"].apply(lambda x:0 if x=='<=50K.' else 1)\n",
    "# separating the feature vecotrs and the target values\n",
    "X_test = test_copy.drop('income', axis =1)\n",
    "y_test = test_copy['income'].values\n",
    "# preprocess the test data using the full pipeline\n",
    "# here we set the type_df param to 'test'\n",
    "X_test = full_pipeline.transform(X_test)\n",
    "\n",
    "\n",
    "counter = Counter(y_train)\n",
    "for k,v in counter.items():\n",
    "    per = v / len(y_train) * 100\n",
    "    print('Class=%s, Count=%d, Percentage=%.2f%%' % (k, v, per))\n",
    "    \n",
    "num_features = X_train.shape[-1]\n",
    "num_classes = len(set(y_train))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "initial_model = XGBClassifier(num_classes= num_classes, reg_lambda=5, \n",
    "                              learning_rate=0.5, max_depth=10, n_estimators=300, device = device)\n",
    "n_repeat = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3bdeeaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15060, 13)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdf5bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly sample retain and forget sets\n",
    "forget_ratios = [0.05, 0.1, 0.2]\n",
    "for forget_ratio in forget_ratios:\n",
    "    idxs = np.arange(len(y_train))\n",
    "    random.shuffle(idxs)\n",
    "    m = int(len(y_train)*forget_ratio)\n",
    "    retain_idxs = idxs[m:]\n",
    "    forget_idxs = idxs[:m]\n",
    "    X_retain = X_train[retain_idxs]\n",
    "    y_retain = y_train[retain_idxs]\n",
    "    X_forget = X_train[forget_idxs]\n",
    "    y_forget = y_train[forget_idxs]\n",
    "\n",
    "\n",
    "    # Step 2: Define and train M on D\n",
    "    train_accs = []\n",
    "    test_accs = []\n",
    "    mia_aucs = []\n",
    "    mia_advs = []\n",
    "    runtimes = []\n",
    "\n",
    "    for r in range(n_repeat):\n",
    "        model = copy.deepcopy(initial_model)\n",
    "        t0 = time.time()\n",
    "        torch.cuda.empty_cache()\n",
    "        model.fit(X_train, y_train)\n",
    "        t1 = time.time()\n",
    "        rt = t1-t0\n",
    "        runtimes.append(rt)\n",
    "\n",
    "        # Evaluate the model accuracy, and MIA\n",
    "        # Accuracy\n",
    "        train_acc = metrics.accuracy_score(y_train, model.predict(X_train))\n",
    "        test_acc = metrics.accuracy_score(y_test, model.predict(X_test))\n",
    "        train_accs.append(100.0*train_acc)\n",
    "        test_accs.append(100.0*test_acc)\n",
    "        #MIA\n",
    "        idxs = np.arange(len(y_test))\n",
    "        random.shuffle(idxs)\n",
    "        rand_idxs = idxs[:m]\n",
    "\n",
    "        test_preds = model.predict_proba(X_test)\n",
    "        forget_preds = model.predict_proba(X_forget)\n",
    "\n",
    "        # Convert class indices to one-hot encoding\n",
    "        y_test_one_hot = encoder.fit_transform(y_test.reshape(-1, 1))\n",
    "        y_forget_one_hot = encoder.transform(y_forget.reshape(-1, 1))\n",
    "\n",
    "        loss_test = np.array([metrics.log_loss(y_test_one_hot[i], test_preds[i]) for i in range(len(y_test))])\n",
    "        loss_forget = np.array([metrics.log_loss(y_forget_one_hot[i], forget_preds[i]) for i in range(len(y_forget))])\n",
    "\n",
    "        attack_result = tf_attack(logits_train = forget_preds, logits_test = test_preds[rand_idxs], \n",
    "                                  loss_train = loss_forget, loss_test = loss_test[rand_idxs], \n",
    "                                  train_labels = y_forget, test_labels = y_test[rand_idxs])\n",
    "\n",
    "        auc = attack_result.get_result_with_max_auc().get_auc()\n",
    "        adv = attack_result.get_result_with_max_attacker_advantage().get_attacker_advantage()\n",
    "        mia_aucs.append(100.0*auc)\n",
    "        mia_advs.append(100.0*adv)\n",
    "\n",
    "    mean_runtime = np.mean(runtimes)\n",
    "    std_runtime = np.std(runtimes)\n",
    "    mean_train_acc = np.mean(train_accs)\n",
    "    std_train_acc = np.std(train_accs)\n",
    "    mean_test_acc = np.mean(test_accs)\n",
    "    std_test_acc = np.std(test_accs)\n",
    "    mean_mia_auc = np.mean(mia_aucs)\n",
    "    std_mia_auc = np.std(mia_aucs)\n",
    "    mean_mia_adv = np.mean(mia_advs)\n",
    "    std_mia_adv = np.std(mia_advs)\n",
    "\n",
    "    # Print the results\n",
    "    print('Training M on D time:{:0.2f}(±{:0.2f}) seconds'.format(mean_runtime, std_runtime))\n",
    "    print('Train accuracy:{:0.2f}(±{:0.2f})%'.format(mean_train_acc, std_train_acc))\n",
    "    print('Test accuracy:{:0.2f}(±{:0.2f})%'.format(mean_test_acc, std_test_acc))\n",
    "    print('MIA AUC:{:0.2f}(±{:0.2f})%'.format(mean_mia_auc, std_mia_auc))\n",
    "    print('MIA Advantage:{:0.2f}(±{:0.2f})%'.format(mean_mia_adv, std_mia_adv))\n",
    "\n",
    "    # Save to CSV\n",
    "    csv_file_path = 'results/adult/xgb_m_d_fr={}.csv'.format(forget_ratio)\n",
    "\n",
    "    with open(csv_file_path, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Metric', 'Mean', 'Standard Deviation'])\n",
    "        writer.writerow(['Training Time', mean_runtime, std_runtime])\n",
    "        writer.writerow(['Train Accuracy', mean_train_acc, std_train_acc])\n",
    "        writer.writerow(['Test Accuracy', mean_test_acc, std_test_acc])\n",
    "        writer.writerow(['MIA AUC', mean_mia_auc, std_mia_auc])\n",
    "        writer.writerow(['MIA Advantage', mean_mia_adv, std_mia_adv])\n",
    "\n",
    "    ######################################################################################################\n",
    "    # Step 3: Train M_retain on D_retain\n",
    "    retain_accs = []\n",
    "    forget_accs = []\n",
    "    test_accs = []\n",
    "    mia_aucs = []\n",
    "    mia_advs = []\n",
    "    runtimes = []\n",
    "    for r in range(n_repeat):\n",
    "        model_ret = copy.deepcopy(initial_model)\n",
    "        t0 = time.time()\n",
    "        torch.cuda.empty_cache()\n",
    "        model_ret.fit(X_retain, y_retain)\n",
    "        t1 = time.time()\n",
    "        rt = t1-t0\n",
    "        runtimes.append(rt)\n",
    "\n",
    "        # Evaluate the model accuracy, and MIA\n",
    "        # Accuracy\n",
    "        retain_acc = metrics.accuracy_score(y_retain, model_ret.predict(X_retain))\n",
    "        forget_acc = metrics.accuracy_score(y_forget, model_ret.predict(X_forget))\n",
    "        test_acc = metrics.accuracy_score(y_test, model_ret.predict(X_test))\n",
    "        retain_accs.append(100.0*retain_acc)\n",
    "        forget_accs.append(100.0*forget_acc)\n",
    "        test_accs.append(100.0*test_acc)\n",
    "        #MIA\n",
    "        idxs = np.arange(len(y_test))\n",
    "        random.shuffle(idxs)\n",
    "        rand_idxs = idxs[:m]\n",
    "\n",
    "        test_preds = model_ret.predict_proba(X_test)\n",
    "        forget_preds = model_ret.predict_proba(X_forget)\n",
    "        loss_test = np.array([metrics.log_loss(y_test_one_hot[i], test_preds[i]) for i in range(len(y_test))])\n",
    "        loss_forget = np.array([metrics.log_loss(y_forget_one_hot[i], forget_preds[i]) for i in range(len(y_forget))])\n",
    "\n",
    "        attack_result = tf_attack(logits_train = forget_preds, logits_test = test_preds[rand_idxs], \n",
    "                                  loss_train = loss_forget, loss_test = loss_test[rand_idxs], \n",
    "                                  train_labels = y_forget, test_labels = y_test[rand_idxs])\n",
    "\n",
    "        auc = attack_result.get_result_with_max_auc().get_auc()\n",
    "        adv = attack_result.get_result_with_max_attacker_advantage().get_attacker_advantage()\n",
    "        mia_aucs.append(100.0*auc)\n",
    "        mia_advs.append(100.0*adv)\n",
    "\n",
    "\n",
    "    mean_retrain_runtime = np.mean(runtimes)\n",
    "    std_retrain_runtime = np.std(runtimes)\n",
    "    mean_retain_acc = np.mean(retain_accs)\n",
    "    std_retain_acc = np.std(retain_accs)\n",
    "    mean_forget_acc = np.mean(forget_accs)\n",
    "    std_forget_acc = np.std(forget_accs)\n",
    "    mean_retrain_test_acc = np.mean(test_accs)\n",
    "    std_retrain_test_acc = np.std(test_accs)\n",
    "    mean_retrain_mia_auc = np.mean(mia_aucs)\n",
    "    std_retrain_mia_auc = np.std(mia_aucs)\n",
    "    mean_retrain_mia_adv = np.mean(mia_advs)\n",
    "    std_retrain_mia_adv = np.std(mia_advs)\n",
    "\n",
    "    # Print the results\n",
    "    print('Retraining M on D_ret time:{:0.2f}(±{:0.2f}) seconds'.format(mean_retrain_runtime, std_retrain_runtime))\n",
    "    print('Retain accuracy:{:0.2f}(±{:0.2f})%'.format(mean_retain_acc, std_retain_acc))\n",
    "    print('Forget accuracy:{:0.2f}(±{:0.2f})%'.format(mean_forget_acc, std_forget_acc))\n",
    "    print('Test accuracy:{:0.2f}(±{:0.2f})%'.format(mean_retrain_test_acc, std_retrain_test_acc))\n",
    "    print('MIA AUC:{:0.2f}(±{:0.2f})%'.format(mean_retrain_mia_auc, std_retrain_mia_auc))\n",
    "    print('MIA Advantage:{:0.2f}(±{:0.2f})%'.format(mean_retrain_mia_adv, std_retrain_mia_adv))\n",
    "\n",
    "    # Save to CSV\n",
    "    csv_retrain_file_path = 'results/adult/xgb_mret_dret_fr={}.csv'.format(forget_ratio)\n",
    "\n",
    "    with open(csv_retrain_file_path, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Metric', 'Mean', 'Standard Deviation'])\n",
    "        writer.writerow(['Retraining Time', mean_retrain_runtime, std_retrain_runtime])\n",
    "        writer.writerow(['Retain Accuracy', mean_retain_acc, std_retain_acc])\n",
    "        writer.writerow(['Forget Accuracy', mean_forget_acc, std_forget_acc])\n",
    "        writer.writerow(['Test Accuracy', mean_retrain_test_acc, std_retrain_test_acc])\n",
    "        writer.writerow(['MIA AUC', mean_retrain_mia_auc, std_retrain_mia_auc])\n",
    "        writer.writerow(['MIA Advantage', mean_retrain_mia_adv, std_retrain_mia_adv])\n",
    "        \n",
    "######################################################################################################\n",
    "    # Step 1: k-anonymize and prepare D_k\n",
    "    ft_epochs_list = [5, 10, 20]\n",
    "    for ft_epochs in ft_epochs_list:\n",
    "        K = [3, 5, 10, 20, 80]\n",
    "        for k in K:\n",
    "            runtimes_k = []\n",
    "            t0 = time.time()\n",
    "            centroids, clusters, labels, X_train_k, y_train_k = mdav(copy.deepcopy(X_train), copy.deepcopy(y_train), k)\n",
    "            print_stats(clusters, centroids)\n",
    "            print('Shape of X_train_k:{}, y_train_k:{}'.format(X_train_k.shape, y_train_k.shape))\n",
    "             # Create TensorDatasets\n",
    "            t1 = time.time()\n",
    "            rt_k = t1- t0\n",
    "            runtimes_k.append(rt_k)\n",
    "\n",
    "            train_accs_k = []\n",
    "            test_accs_k = []\n",
    "            mia_aucs_k = []\n",
    "            mia_advs_k = []\n",
    "            runtimes_train_k = []\n",
    "\n",
    "            train_accs_k_D = []\n",
    "            test_accs_k_D = []\n",
    "            mia_aucs_k_D = []\n",
    "            mia_advs_k_D = []\n",
    "            runtimes_train_k_D = []\n",
    "\n",
    "            retain_accs_k_ret = []\n",
    "            forget_accs_k_ret = []\n",
    "            test_accs_k_ret = []\n",
    "            mia_aucs_k_ret = []\n",
    "            mia_advs_k_ret = []\n",
    "            runtimes_train_k_ret = []\n",
    "\n",
    "            for r in range(n_repeat):\n",
    "                model_k = copy.deepcopy(initial_model)\n",
    "                t0 = time.time()\n",
    "                torch.cuda.empty_cache()\n",
    "                model_k.fit(X_train_k, y_train_k)\n",
    "                t1 = time.time()\n",
    "                rt_train = t1- t0\n",
    "                runtimes_train_k.append(rt_train)\n",
    "\n",
    "                # Evaluate the model accuracy, and MIA\n",
    "                # Accuracy\n",
    "                train_acc = metrics.accuracy_score(y_train_k, model_k.predict(X_train_k))\n",
    "                test_acc = metrics.accuracy_score(y_test, model_k.predict(X_test))\n",
    "                train_accs_k.append(100.0*train_acc)\n",
    "                test_accs_k.append(100.0*test_acc)\n",
    "                #MIA\n",
    "                idxs = np.arange(len(y_test))\n",
    "                random.shuffle(idxs)\n",
    "                rand_idxs = idxs[:m]\n",
    "\n",
    "                test_preds = model_k.predict_proba(X_test)\n",
    "                forget_preds = model_k.predict_proba(X_forget)\n",
    "\n",
    "                # Convert class indices to one-hot encoding\n",
    "                y_test_one_hot = encoder.fit_transform(y_test.reshape(-1, 1))\n",
    "                y_forget_one_hot = encoder.transform(y_forget.reshape(-1, 1))\n",
    "\n",
    "                loss_test = np.array([metrics.log_loss(y_test_one_hot[i], test_preds[i]) for i in range(len(y_test))])\n",
    "                loss_forget = np.array([metrics.log_loss(y_forget_one_hot[i], forget_preds[i]) for i in range(len(y_forget))])\n",
    "\n",
    "                attack_result = tf_attack(logits_train = forget_preds, logits_test = test_preds[rand_idxs], \n",
    "                                          loss_train = loss_forget, loss_test = loss_test[rand_idxs], \n",
    "                                          train_labels = y_forget, test_labels = y_test[rand_idxs])\n",
    "\n",
    "                auc = attack_result.get_result_with_max_auc().get_auc()\n",
    "                adv = attack_result.get_result_with_max_attacker_advantage().get_attacker_advantage()\n",
    "                mia_aucs_k.append(100.0*auc)\n",
    "                mia_advs_k.append(100.0*adv)\n",
    "\n",
    "                model_k_D = copy.deepcopy(initial_model)\n",
    "                model_k_D.set_params(learning_rate = 0.5, n_estimators=ft_epochs)\n",
    "                t0 = time.time()\n",
    "                torch.cuda.empty_cache()\n",
    "                model_k_D.fit(X_train, y_train, xgb_model=model_k)\n",
    "                t1 = time.time()\n",
    "                rt = t1-t0\n",
    "                runtimes_train_k_D.append(rt)\n",
    "\n",
    "                # Evaluate the model accuracy, and MIA\n",
    "                # Accuracy\n",
    "                train_acc = metrics.accuracy_score(y_train, model_k_D.predict(X_train))\n",
    "                test_acc = metrics.accuracy_score(y_test, model_k_D.predict(X_test))\n",
    "                train_accs_k_D.append(100.0*train_acc)\n",
    "                test_accs_k_D.append(100.0*test_acc)\n",
    "                #MIA\n",
    "                idxs = np.arange(len(y_test))\n",
    "                random.shuffle(idxs)\n",
    "                rand_idxs = idxs[:m]\n",
    "\n",
    "                test_preds = model_k_D.predict_proba(X_test)\n",
    "                forget_preds = model_k_D.predict_proba(X_forget)\n",
    "\n",
    "                # Convert class indices to one-hot encoding\n",
    "                y_test_one_hot = encoder.fit_transform(y_test.reshape(-1, 1))\n",
    "                y_forget_one_hot = encoder.transform(y_forget.reshape(-1, 1))\n",
    "\n",
    "                loss_test = np.array([metrics.log_loss(y_test_one_hot[i], test_preds[i]) for i in range(len(y_test))])\n",
    "                loss_forget = np.array([metrics.log_loss(y_forget_one_hot[i], forget_preds[i]) for i in range(len(y_forget))])\n",
    "\n",
    "                attack_result = tf_attack(logits_train = forget_preds, logits_test = test_preds[rand_idxs], \n",
    "                                          loss_train = loss_forget, loss_test = loss_test[rand_idxs], \n",
    "                                          train_labels = y_forget, test_labels = y_test[rand_idxs])\n",
    "\n",
    "                auc = attack_result.get_result_with_max_auc().get_auc()\n",
    "                adv = attack_result.get_result_with_max_attacker_advantage().get_attacker_advantage()\n",
    "                mia_aucs_k_D.append(100.0*auc)\n",
    "                mia_advs_k_D.append(100.0*adv)\n",
    "\n",
    "                model_k_ret = copy.deepcopy(initial_model)\n",
    "                model_k_ret.set_params(learning_rate = 0.5, n_estimators=ft_epochs)\n",
    "                t0 = time.time()\n",
    "                torch.cuda.empty_cache()\n",
    "                model_k_ret.fit(X_retain, y_retain, xgb_model=model_k)\n",
    "                t1 = time.time()\n",
    "                rt = t1-t0\n",
    "                runtimes_train_k_ret.append(rt)\n",
    "                # Evaluate the model accuracy, and MIA\n",
    "                # Accuracy\n",
    "                retain_acc = metrics.accuracy_score(y_retain, model_k_ret.predict(X_retain))\n",
    "                forget_acc = metrics.accuracy_score(y_forget, model_k_ret.predict(X_forget))\n",
    "                test_acc = metrics.accuracy_score(y_test, model_k_ret.predict(X_test))\n",
    "                retain_accs_k_ret.append(100.0*retain_acc)\n",
    "                forget_accs_k_ret.append(100.0*forget_acc)\n",
    "                test_accs_k_ret.append(100.0*test_acc)\n",
    "                #MIA\n",
    "                idxs = np.arange(len(y_test))\n",
    "                random.shuffle(idxs)\n",
    "                rand_idxs = idxs[:m]\n",
    "\n",
    "                test_preds = model_k_ret.predict_proba(X_test)\n",
    "                forget_preds = model_k_ret.predict_proba(X_forget)\n",
    "                loss_test = np.array([metrics.log_loss(y_test_one_hot[i], test_preds[i]) for i in range(len(y_test))])\n",
    "                loss_forget = np.array([metrics.log_loss(y_forget_one_hot[i], forget_preds[i]) for i in range(len(y_forget))])\n",
    "\n",
    "                attack_result = tf_attack(logits_train = forget_preds, logits_test = test_preds[rand_idxs], \n",
    "                                          loss_train = loss_forget, loss_test = loss_test[rand_idxs], \n",
    "                                          train_labels = y_forget, test_labels = y_test[rand_idxs])\n",
    "\n",
    "                auc = attack_result.get_result_with_max_auc().get_auc()\n",
    "                adv = attack_result.get_result_with_max_attacker_advantage().get_attacker_advantage()\n",
    "                mia_aucs_k_ret.append(100.0*auc)\n",
    "                mia_advs_k_ret.append(100.0*adv)\n",
    "\n",
    "\n",
    "            # Anonymizing D and training M_k on D_k\n",
    "            mean_anonymize_time = np.mean(runtimes_k)\n",
    "            std_anonymize_time = np.std(runtimes_k)\n",
    "            mean_train_k_time = np.mean(runtimes_train_k)\n",
    "            std_train_k_time = np.std(runtimes_train_k)\n",
    "            mean_train_k_acc = np.mean(train_accs_k)\n",
    "            std_train_k_acc = np.std(train_accs_k)\n",
    "            mean_test_k_acc = np.mean(test_accs_k)\n",
    "            std_test_k_acc = np.std(test_accs_k)\n",
    "            mean_mia_k_auc = np.mean(mia_aucs_k)\n",
    "            std_mia_k_auc = np.std(mia_aucs_k)\n",
    "            mean_mia_k_adv = np.mean(mia_advs_k)\n",
    "            std_mia_k_adv = np.std(mia_advs_k)\n",
    "\n",
    "            # Finetuning M_k on D\n",
    "            mean_finetune_D_time = np.mean(runtimes_train_k_D)\n",
    "            std_finetune_D_time = np.std(runtimes_train_k_D)\n",
    "            mean_finetune_D_train_acc = np.mean(train_accs_k_D)\n",
    "            std_finetune_D_train_acc = np.std(train_accs_k_D)\n",
    "            mean_finetune_D_test_acc = np.mean(test_accs_k_D)\n",
    "            std_finetune_D_test_acc = np.std(test_accs_k_D)\n",
    "            mean_finetune_D_mia_auc = np.mean(mia_aucs_k_D)\n",
    "            std_finetune_D_mia_auc = np.std(mia_aucs_k_D)\n",
    "            mean_finetune_D_mia_adv = np.mean(mia_advs_k_D)\n",
    "            std_finetune_D_mia_adv = np.std(mia_advs_k_D)\n",
    "\n",
    "            # Finetuning M_k on D_ret\n",
    "            mean_finetune_D_ret_time = np.mean(runtimes_train_k_ret)\n",
    "            std_finetune_D_ret_time = np.std(runtimes_train_k_ret)\n",
    "            mean_finetune_D_ret_train_acc = np.mean(retain_accs_k_ret)\n",
    "            std_finetune_D_ret_train_acc = np.std(retain_accs_k_ret)\n",
    "            mean_finetune_D_ret_forget_acc = np.mean(forget_accs_k_ret)\n",
    "            std_finetune_D_ret_forget_acc = np.std(forget_accs_k_ret)\n",
    "            mean_finetune_D_ret_test_acc = np.mean(test_accs_k_ret)\n",
    "            std_finetune_D_ret_test_acc = np.std(test_accs_k_ret)\n",
    "            mean_finetune_D_ret_mia_auc = np.mean(mia_aucs_k_ret)\n",
    "            std_finetune_D_ret_mia_auc = np.std(mia_aucs_k_ret)\n",
    "            mean_finetune_D_ret_mia_adv = np.mean(mia_advs_k_ret)\n",
    "            std_finetune_D_ret_mia_adv = np.std(mia_advs_k_ret)\n",
    "\n",
    "\n",
    "            # Print the results\n",
    "            print('----------------------------------------')\n",
    "            print('k=', k, 'Fine-tuning epochs=', ft_epochs)\n",
    "            print('----------------------------------------')\n",
    "            print('-----Anonymizing D and training M_k on D_k-----')\n",
    "            print('Anonymizing D time:{:0.2f}(±{:0.2f})'.format(mean_anonymize_time, std_anonymize_time))\n",
    "            print('Training M_k on D_k time:{:0.2f}(±{:0.2f})'.format(mean_train_k_time, std_train_k_time))\n",
    "            print('Train accuracy:{:0.2f}(±{:0.2f})%'.format(mean_train_k_acc, std_train_k_acc))\n",
    "            print('Test accuracy:{:0.2f}(±{:0.2f})%'.format(mean_test_k_acc, std_test_k_acc))\n",
    "            print('MIA AUC:{:0.2f}(±{:0.2f})%'.format(mean_mia_k_auc, std_mia_k_auc))\n",
    "            print('MIA Advantage:{:0.2f}(±{:0.2f})%'.format(mean_mia_k_adv, std_mia_k_adv))\n",
    "\n",
    "            print('-----Finetuning M_k on D-----')\n",
    "            print('Training M_k on D time:{:0.2f}(±{:0.2f})'.format(mean_finetune_D_time, std_finetune_D_time))\n",
    "            print('Train accuracy:{:0.2f}(±{:0.2f})%'.format(mean_finetune_D_train_acc, std_finetune_D_train_acc))\n",
    "            print('Test accuracy:{:0.2f}(±{:0.2f})%'.format(mean_finetune_D_test_acc, std_finetune_D_test_acc))\n",
    "            print('MIA AUC:{:0.2f}(±{:0.2f})%'.format(mean_finetune_D_mia_auc, std_finetune_D_mia_auc))\n",
    "            print('MIA Advantage:{:0.2f}(±{:0.2f})%'.format(mean_finetune_D_mia_adv, std_finetune_D_mia_adv))\n",
    "\n",
    "            print('-----Finetuning M_k on D_ret-----')\n",
    "            print('Finetuning M_k on D_retain time:{:0.2f}(±{:0.2f}) seconds'.format(mean_finetune_D_ret_time, std_finetune_D_ret_time))\n",
    "            print('Retain accuracy:{:0.2f}(±{:0.2f})%'.format(mean_finetune_D_ret_train_acc, std_finetune_D_ret_train_acc))\n",
    "            print('Forget accuracy:{:0.2f}(±{:0.2f})%'.format(mean_finetune_D_ret_forget_acc, std_finetune_D_ret_forget_acc))\n",
    "            print('Test accuracy:{:0.2f}(±{:0.2f})%'.format(mean_finetune_D_ret_test_acc, std_finetune_D_ret_test_acc))\n",
    "            print('MIA AUC:{:0.2f}(±{:0.2f})%'.format(mean_finetune_D_ret_mia_auc, std_finetune_D_ret_mia_auc))\n",
    "            print('MIA Advantage:{:0.2f}(±{:0.2f})%'.format(mean_finetune_D_ret_mia_adv, std_finetune_D_ret_mia_adv))\n",
    "            print('----------------------------------------')\n",
    "\n",
    "            # Save to CSV\n",
    "            csv_anonymize_file_path = 'results/adult/xgb_mk={}_dk_fr={}.csv'.format(k, forget_ratio)\n",
    "            csv_finetune_D_file_path = 'results/adult/xgb_mk={}_d_fr={}_epochs={}.csv'.format(k, forget_ratio, ft_epochs)\n",
    "            csv_finetune_D_ret_file_path = 'results/adult/xgb_mk={}_dret_fr={}_epochs={}.csv'.format(k, forget_ratio, ft_epochs)\n",
    "\n",
    "            # Writing to CSV for anonymizing, finetuning on D, and finetuning on D_ret\n",
    "            with open(csv_anonymize_file_path, mode='w', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(['Metric', 'Mean', 'Standard Deviation'])\n",
    "                writer.writerow(['Anonymizing Time', mean_anonymize_time, std_anonymize_time])\n",
    "                writer.writerow(['Training M_k on D_k Time', mean_train_k_time, std_train_k_time])\n",
    "                writer.writerow(['Train Accuracy', mean_train_k_acc, std_train_k_acc])\n",
    "                writer.writerow(['Test Accuracy', mean_test_k_acc, std_test_k_acc])\n",
    "                writer.writerow(['MIA AUC', mean_mia_k_auc, std_mia_k_auc])\n",
    "                writer.writerow(['MIA Advantage', mean_mia_k_adv, std_mia_k_adv])\n",
    "\n",
    "            with open(csv_finetune_D_file_path, mode='w', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(['Metric', 'Mean', 'Standard Deviation'])\n",
    "                writer.writerow(['Training M_k on D Time', mean_finetune_D_time, std_finetune_D_time])\n",
    "                writer.writerow(['Train Accuracy', mean_finetune_D_train_acc, std_finetune_D_train_acc])\n",
    "                writer.writerow(['Test Accuracy', mean_finetune_D_test_acc, std_finetune_D_test_acc])\n",
    "                writer.writerow(['MIA AUC', mean_finetune_D_mia_auc, std_finetune_D_mia_auc])\n",
    "                writer.writerow(['MIA Advantage', mean_finetune_D_mia_adv, std_finetune_D_mia_adv])\n",
    "\n",
    "            with open(csv_finetune_D_ret_file_path, mode='w', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(['Metric', 'Mean', 'Standard Deviation'])\n",
    "                writer.writerow(['Finetuning M_k on D_retain Time', mean_finetune_D_ret_time, std_finetune_D_ret_time])\n",
    "                writer.writerow(['Retain Accuracy', mean_finetune_D_ret_train_acc, std_finetune_D_ret_train_acc])\n",
    "                writer.writerow(['Forget Accuracy', mean_finetune_D_ret_forget_acc, std_finetune_D_ret_forget_acc])\n",
    "                writer.writerow(['Test Accuracy', mean_finetune_D_ret_test_acc, std_finetune_D_ret_test_acc])\n",
    "                writer.writerow(['MIA AUC', mean_finetune_D_ret_mia_auc, std_finetune_D_ret_mia_auc])\n",
    "                writer.writerow(['MIA Advantage', mean_finetune_D_ret_mia_adv, std_finetune_D_ret_mia_adv])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ebd80e",
   "metadata": {},
   "source": [
    "# Differential privacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2650da6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly sample retain and forget sets\n",
    "forget_ratios = [0.05, 0.1, 0.2]\n",
    "for forget_ratio in forget_ratios:\n",
    "    idxs = np.arange(len(y_train))\n",
    "    random.shuffle(idxs)\n",
    "    m = int(len(y_train)*forget_ratio)\n",
    "    retain_idxs = idxs[m:]\n",
    "    forget_idxs = idxs[:m]\n",
    "    X_retain = X_train[retain_idxs]\n",
    "    y_retain = y_train[retain_idxs]\n",
    "    X_forget = X_train[forget_idxs]\n",
    "    y_forget = y_train[forget_idxs]\n",
    "\n",
    "    for r in range(n_repeat):\n",
    "        ft_epochs_list = [5, 10, 20]\n",
    "        for ft_epochs in ft_epochs_list:\n",
    "            EPS = [0.5, 2.5, 5.0, 25.0, 50.0, 100.0]\n",
    "            for eps in EPS:\n",
    "                dp_train_data = pd.read_csv('dp_data/adult/dp_adult_eps={}.csv'.format(eps), sep=r' *, *', engine='python', na_values='?')\n",
    "                dp_train_data.head()\n",
    "                # Drop useless columns\n",
    "                dp_train_data.drop(['fnlwgt', 'education'], axis=1, inplace=True)\n",
    "                dp_train_data.dropna(inplace=True)\n",
    "                # convert the income column to 0 or 1 and then drop the column for the feature vectors\n",
    "                dp_train_data[\"income\"] = dp_train_data[\"income\"].apply(lambda x:0 if x=='<=50K' else 1)\n",
    "                # creating the feature vector \n",
    "                X_train_dp = dp_train_data.drop('income', axis =1)\n",
    "                # target values\n",
    "                y_train_dp = dp_train_data['income'].values\n",
    "                # pass the data through the full_pipeline\n",
    "                X_train_dp = full_pipeline.fit_transform(X_train_dp)\n",
    "\n",
    "                train_accs_k = []\n",
    "                test_accs_k = []\n",
    "                mia_aucs_k = []\n",
    "                mia_advs_k = []\n",
    "                runtimes_train_k = []\n",
    "\n",
    "                train_accs_k_D = []\n",
    "                test_accs_k_D = []\n",
    "                mia_aucs_k_D = []\n",
    "                mia_advs_k_D = []\n",
    "                runtimes_train_k_D = []\n",
    "\n",
    "                retain_accs_k_ret = []\n",
    "                forget_accs_k_ret = []\n",
    "                test_accs_k_ret = []\n",
    "                mia_aucs_k_ret = []\n",
    "                mia_advs_k_ret = []\n",
    "                runtimes_train_k_ret = []\n",
    "\n",
    "                for r in range(n_repeat):\n",
    "                    model_k = copy.deepcopy(initial_model)\n",
    "                    t0 = time.time()\n",
    "                    torch.cuda.empty_cache()\n",
    "                    model_k.fit(X_train_dp, y_train_dp)\n",
    "                    t1 = time.time()\n",
    "                    rt_train = t1- t0\n",
    "                    runtimes_train_k.append(rt_train)\n",
    "\n",
    "                    # Evaluate the model accuracy, and MIA\n",
    "                    # Accuracy\n",
    "                    train_acc = metrics.accuracy_score(y_train_dp, model_k.predict(X_train_dp))\n",
    "                    test_acc = metrics.accuracy_score(y_test, model_k.predict(X_test))\n",
    "                    train_accs_k.append(100.0*train_acc)\n",
    "                    test_accs_k.append(100.0*test_acc)\n",
    "                    #MIA\n",
    "                    idxs = np.arange(len(y_test))\n",
    "                    random.shuffle(idxs)\n",
    "                    rand_idxs = idxs[:m]\n",
    "\n",
    "                    test_preds = model_k.predict_proba(X_test)\n",
    "                    forget_preds = model_k.predict_proba(X_forget)\n",
    "\n",
    "                    # Convert class indices to one-hot encoding\n",
    "                    y_test_one_hot = encoder.fit_transform(y_test.reshape(-1, 1))\n",
    "                    y_forget_one_hot = encoder.transform(y_forget.reshape(-1, 1))\n",
    "\n",
    "                    loss_test = np.array([metrics.log_loss(y_test_one_hot[i], test_preds[i]) for i in range(len(y_test))])\n",
    "                    loss_forget = np.array([metrics.log_loss(y_forget_one_hot[i], forget_preds[i]) for i in range(len(y_forget))])\n",
    "\n",
    "                    attack_result = tf_attack(logits_train = forget_preds, logits_test = test_preds[rand_idxs], \n",
    "                                              loss_train = loss_forget, loss_test = loss_test[rand_idxs], \n",
    "                                              train_labels = y_forget, test_labels = y_test[rand_idxs])\n",
    "\n",
    "                    auc = attack_result.get_result_with_max_auc().get_auc()\n",
    "                    adv = attack_result.get_result_with_max_attacker_advantage().get_attacker_advantage()\n",
    "                    mia_aucs_k.append(100.0*auc)\n",
    "                    mia_advs_k.append(100.0*adv)\n",
    "\n",
    "                    model_k_D = copy.deepcopy(initial_model)\n",
    "                    model_k_D.set_params(learning_rate = 0.5, n_estimators=ft_epochs)\n",
    "                    t0 = time.time()\n",
    "                    torch.cuda.empty_cache()\n",
    "                    model_k_D.fit(X_train, y_train, xgb_model=model_k)\n",
    "                    t1 = time.time()\n",
    "                    rt = t1-t0\n",
    "                    runtimes_train_k_D.append(rt)\n",
    "\n",
    "                    # Evaluate the model accuracy, and MIA\n",
    "                    # Accuracy\n",
    "                    train_acc = metrics.accuracy_score(y_train, model_k_D.predict(X_train))\n",
    "                    test_acc = metrics.accuracy_score(y_test, model_k_D.predict(X_test))\n",
    "                    train_accs_k_D.append(100.0*train_acc)\n",
    "                    test_accs_k_D.append(100.0*test_acc)\n",
    "                    #MIA\n",
    "                    idxs = np.arange(len(y_test))\n",
    "                    random.shuffle(idxs)\n",
    "                    rand_idxs = idxs[:m]\n",
    "\n",
    "                    test_preds = model_k_D.predict_proba(X_test)\n",
    "                    forget_preds = model_k_D.predict_proba(X_forget)\n",
    "\n",
    "                    # Convert class indices to one-hot encoding\n",
    "                    y_test_one_hot = encoder.fit_transform(y_test.reshape(-1, 1))\n",
    "                    y_forget_one_hot = encoder.transform(y_forget.reshape(-1, 1))\n",
    "\n",
    "                    loss_test = np.array([metrics.log_loss(y_test_one_hot[i], test_preds[i]) for i in range(len(y_test))])\n",
    "                    loss_forget = np.array([metrics.log_loss(y_forget_one_hot[i], forget_preds[i]) for i in range(len(y_forget))])\n",
    "\n",
    "                    attack_result = tf_attack(logits_train = forget_preds, logits_test = test_preds[rand_idxs], \n",
    "                                              loss_train = loss_forget, loss_test = loss_test[rand_idxs], \n",
    "                                              train_labels = y_forget, test_labels = y_test[rand_idxs])\n",
    "\n",
    "                    auc = attack_result.get_result_with_max_auc().get_auc()\n",
    "                    adv = attack_result.get_result_with_max_attacker_advantage().get_attacker_advantage()\n",
    "                    mia_aucs_k_D.append(100.0*auc)\n",
    "                    mia_advs_k_D.append(100.0*adv)\n",
    "\n",
    "                    model_k_ret = copy.deepcopy(initial_model)\n",
    "                    model_k_ret.set_params(learning_rate = 0.5, n_estimators=ft_epochs)\n",
    "                    t0 = time.time()\n",
    "                    torch.cuda.empty_cache()\n",
    "                    model_k_ret.fit(X_retain, y_retain, xgb_model=model_k)\n",
    "                    t1 = time.time()\n",
    "                    rt = t1-t0\n",
    "                    runtimes_train_k_ret.append(rt)\n",
    "                    # Evaluate the model accuracy, and MIA\n",
    "                    # Accuracy\n",
    "                    retain_acc = metrics.accuracy_score(y_retain, model_k_ret.predict(X_retain))\n",
    "                    forget_acc = metrics.accuracy_score(y_forget, model_k_ret.predict(X_forget))\n",
    "                    test_acc = metrics.accuracy_score(y_test, model_k_ret.predict(X_test))\n",
    "                    retain_accs_k_ret.append(100.0*retain_acc)\n",
    "                    forget_accs_k_ret.append(100.0*forget_acc)\n",
    "                    test_accs_k_ret.append(100.0*test_acc)\n",
    "                    #MIA\n",
    "                    idxs = np.arange(len(y_test))\n",
    "                    random.shuffle(idxs)\n",
    "                    rand_idxs = idxs[:m]\n",
    "\n",
    "                    test_preds = model_k_ret.predict_proba(X_test)\n",
    "                    forget_preds = model_k_ret.predict_proba(X_forget)\n",
    "                    loss_test = np.array([metrics.log_loss(y_test_one_hot[i], test_preds[i]) for i in range(len(y_test))])\n",
    "                    loss_forget = np.array([metrics.log_loss(y_forget_one_hot[i], forget_preds[i]) for i in range(len(y_forget))])\n",
    "\n",
    "                    attack_result = tf_attack(logits_train = forget_preds, logits_test = test_preds[rand_idxs], \n",
    "                                              loss_train = loss_forget, loss_test = loss_test[rand_idxs], \n",
    "                                              train_labels = y_forget, test_labels = y_test[rand_idxs])\n",
    "\n",
    "                    auc = attack_result.get_result_with_max_auc().get_auc()\n",
    "                    adv = attack_result.get_result_with_max_attacker_advantage().get_attacker_advantage()\n",
    "                    mia_aucs_k_ret.append(100.0*auc)\n",
    "                    mia_advs_k_ret.append(100.0*adv)\n",
    "\n",
    "\n",
    "                # Anonymizing D and training M_k on D_k\n",
    "                mean_train_k_time = np.mean(runtimes_train_k)\n",
    "                std_train_k_time = np.std(runtimes_train_k)\n",
    "                mean_train_k_acc = np.mean(train_accs_k)\n",
    "                std_train_k_acc = np.std(train_accs_k)\n",
    "                mean_test_k_acc = np.mean(test_accs_k)\n",
    "                std_test_k_acc = np.std(test_accs_k)\n",
    "                mean_mia_k_auc = np.mean(mia_aucs_k)\n",
    "                std_mia_k_auc = np.std(mia_aucs_k)\n",
    "                mean_mia_k_adv = np.mean(mia_advs_k)\n",
    "                std_mia_k_adv = np.std(mia_advs_k)\n",
    "\n",
    "                # Finetuning M_k on D\n",
    "                mean_finetune_D_time = np.mean(runtimes_train_k_D)\n",
    "                std_finetune_D_time = np.std(runtimes_train_k_D)\n",
    "                mean_finetune_D_train_acc = np.mean(train_accs_k_D)\n",
    "                std_finetune_D_train_acc = np.std(train_accs_k_D)\n",
    "                mean_finetune_D_test_acc = np.mean(test_accs_k_D)\n",
    "                std_finetune_D_test_acc = np.std(test_accs_k_D)\n",
    "                mean_finetune_D_mia_auc = np.mean(mia_aucs_k_D)\n",
    "                std_finetune_D_mia_auc = np.std(mia_aucs_k_D)\n",
    "                mean_finetune_D_mia_adv = np.mean(mia_advs_k_D)\n",
    "                std_finetune_D_mia_adv = np.std(mia_advs_k_D)\n",
    "\n",
    "                # Finetuning M_k on D_ret\n",
    "                mean_finetune_D_ret_time = np.mean(runtimes_train_k_ret)\n",
    "                std_finetune_D_ret_time = np.std(runtimes_train_k_ret)\n",
    "                mean_finetune_D_ret_train_acc = np.mean(retain_accs_k_ret)\n",
    "                std_finetune_D_ret_train_acc = np.std(retain_accs_k_ret)\n",
    "                mean_finetune_D_ret_forget_acc = np.mean(forget_accs_k_ret)\n",
    "                std_finetune_D_ret_forget_acc = np.std(forget_accs_k_ret)\n",
    "                mean_finetune_D_ret_test_acc = np.mean(test_accs_k_ret)\n",
    "                std_finetune_D_ret_test_acc = np.std(test_accs_k_ret)\n",
    "                mean_finetune_D_ret_mia_auc = np.mean(mia_aucs_k_ret)\n",
    "                std_finetune_D_ret_mia_auc = np.std(mia_aucs_k_ret)\n",
    "                mean_finetune_D_ret_mia_adv = np.mean(mia_advs_k_ret)\n",
    "                std_finetune_D_ret_mia_adv = np.std(mia_advs_k_ret)\n",
    "\n",
    "\n",
    "                # Print the results\n",
    "                print('----------------------------------------')\n",
    "                print('Epsilon=', eps, 'Fine-tuning epochs=', ft_epochs)\n",
    "                print('----------------------------------------')\n",
    "                print('-----Anonymizing D and training M_k on D_k-----')\n",
    "                print('Training M_k on D_k time:{:0.2f}(±{:0.2f})'.format(mean_train_k_time, std_train_k_time))\n",
    "                print('Train accuracy:{:0.2f}(±{:0.2f})%'.format(mean_train_k_acc, std_train_k_acc))\n",
    "                print('Test accuracy:{:0.2f}(±{:0.2f})%'.format(mean_test_k_acc, std_test_k_acc))\n",
    "                print('MIA AUC:{:0.2f}(±{:0.2f})%'.format(mean_mia_k_auc, std_mia_k_auc))\n",
    "                print('MIA Advantage:{:0.2f}(±{:0.2f})%'.format(mean_mia_k_adv, std_mia_k_adv))\n",
    "\n",
    "                print('-----Finetuning M_k on D-----')\n",
    "                print('Training M_k on D time:{:0.2f}(±{:0.2f})'.format(mean_finetune_D_time, std_finetune_D_time))\n",
    "                print('Train accuracy:{:0.2f}(±{:0.2f})%'.format(mean_finetune_D_train_acc, std_finetune_D_train_acc))\n",
    "                print('Test accuracy:{:0.2f}(±{:0.2f})%'.format(mean_finetune_D_test_acc, std_finetune_D_test_acc))\n",
    "                print('MIA AUC:{:0.2f}(±{:0.2f})%'.format(mean_finetune_D_mia_auc, std_finetune_D_mia_auc))\n",
    "                print('MIA Advantage:{:0.2f}(±{:0.2f})%'.format(mean_finetune_D_mia_adv, std_finetune_D_mia_adv))\n",
    "\n",
    "                print('-----Finetuning M_k on D_ret-----')\n",
    "                print('Finetuning M_k on D_retain time:{:0.2f}(±{:0.2f}) seconds'.format(mean_finetune_D_ret_time, std_finetune_D_ret_time))\n",
    "                print('Retain accuracy:{:0.2f}(±{:0.2f})%'.format(mean_finetune_D_ret_train_acc, std_finetune_D_ret_train_acc))\n",
    "                print('Forget accuracy:{:0.2f}(±{:0.2f})%'.format(mean_finetune_D_ret_forget_acc, std_finetune_D_ret_forget_acc))\n",
    "                print('Test accuracy:{:0.2f}(±{:0.2f})%'.format(mean_finetune_D_ret_test_acc, std_finetune_D_ret_test_acc))\n",
    "                print('MIA AUC:{:0.2f}(±{:0.2f})%'.format(mean_finetune_D_ret_mia_auc, std_finetune_D_ret_mia_auc))\n",
    "                print('MIA Advantage:{:0.2f}(±{:0.2f})%'.format(mean_finetune_D_ret_mia_adv, std_finetune_D_ret_mia_adv))\n",
    "                print('----------------------------------------')\n",
    "\n",
    "                # Save to CSV\n",
    "                csv_anonymize_file_path = 'results/adult/xgb_mdp_eps={}_fr={}.csv'.format(eps, forget_ratio)\n",
    "                csv_finetune_D_file_path = 'results/adult/xgb_mdpd_eps={}_fr={}_epochs={}.csv'.format(eps, forget_ratio, ft_epochs)\n",
    "                csv_finetune_D_ret_file_path = 'results/adult/xgb_mdpret_eps={}_fr={}_epochs={}.csv'.format(eps, forget_ratio, ft_epochs)\n",
    "\n",
    "                # Writing to CSV for anonymizing, finetuning on D, and finetuning on D_ret\n",
    "                with open(csv_anonymize_file_path, mode='w', newline='') as file:\n",
    "                    writer = csv.writer(file)\n",
    "                    writer.writerow(['Metric', 'Mean', 'Standard Deviation'])\n",
    "                    writer.writerow(['Training M_k on D_k Time', mean_train_k_time, std_train_k_time])\n",
    "                    writer.writerow(['Train Accuracy', mean_train_k_acc, std_train_k_acc])\n",
    "                    writer.writerow(['Test Accuracy', mean_test_k_acc, std_test_k_acc])\n",
    "                    writer.writerow(['MIA AUC', mean_mia_k_auc, std_mia_k_auc])\n",
    "                    writer.writerow(['MIA Advantage', mean_mia_k_adv, std_mia_k_adv])\n",
    "\n",
    "                with open(csv_finetune_D_file_path, mode='w', newline='') as file:\n",
    "                    writer = csv.writer(file)\n",
    "                    writer.writerow(['Metric', 'Mean', 'Standard Deviation'])\n",
    "                    writer.writerow(['Training M_k on D Time', mean_finetune_D_time, std_finetune_D_time])\n",
    "                    writer.writerow(['Train Accuracy', mean_finetune_D_train_acc, std_finetune_D_train_acc])\n",
    "                    writer.writerow(['Test Accuracy', mean_finetune_D_test_acc, std_finetune_D_test_acc])\n",
    "                    writer.writerow(['MIA AUC', mean_finetune_D_mia_auc, std_finetune_D_mia_auc])\n",
    "                    writer.writerow(['MIA Advantage', mean_finetune_D_mia_adv, std_finetune_D_mia_adv])\n",
    "\n",
    "                with open(csv_finetune_D_ret_file_path, mode='w', newline='') as file:\n",
    "                    writer = csv.writer(file)\n",
    "                    writer.writerow(['Metric', 'Mean', 'Standard Deviation'])\n",
    "                    writer.writerow(['Finetuning M_k on D_retain Time', mean_finetune_D_ret_time, std_finetune_D_ret_time])\n",
    "                    writer.writerow(['Retain Accuracy', mean_finetune_D_ret_train_acc, std_finetune_D_ret_train_acc])\n",
    "                    writer.writerow(['Forget Accuracy', mean_finetune_D_ret_forget_acc, std_finetune_D_ret_forget_acc])\n",
    "                    writer.writerow(['Test Accuracy', mean_finetune_D_ret_test_acc, std_finetune_D_ret_test_acc])\n",
    "                    writer.writerow(['MIA AUC', mean_finetune_D_ret_mia_auc, std_finetune_D_ret_mia_auc])\n",
    "                    writer.writerow(['MIA Advantage', mean_finetune_D_ret_mia_adv, std_finetune_D_ret_mia_adv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7499e265",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
